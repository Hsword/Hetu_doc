

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>hetu.gpu_ops package &mdash; Hetu 1.0.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Hetu
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">hetu.gpu_ops package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.AddConst">hetu.gpu_ops.AddConst module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.AddElewise">hetu.gpu_ops.AddElewise module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.AllReduceCommunicate">hetu.gpu_ops.AllReduceCommunicate module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.AvgPool">hetu.gpu_ops.AvgPool module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.BatchMatrixMult">hetu.gpu_ops.BatchMatrixMult module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.BatchNorm">hetu.gpu_ops.BatchNorm module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.BinaryCrossEntropy">hetu.gpu_ops.BinaryCrossEntropy module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Broadcast">hetu.gpu_ops.Broadcast module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.BroadcastShape">hetu.gpu_ops.BroadcastShape module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Concat">hetu.gpu_ops.Concat module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Conv2d">hetu.gpu_ops.Conv2d module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Conv2dBroadcast">hetu.gpu_ops.Conv2dBroadcast module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Conv2dReduceSum">hetu.gpu_ops.Conv2dReduceSum module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.CuSparse">hetu.gpu_ops.CuSparse module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.DataTransfer">hetu.gpu_ops.DataTransfer module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.DistGCN_15d">hetu.gpu_ops.DistGCN_15d module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Division">hetu.gpu_ops.Division module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Dropout">hetu.gpu_ops.Dropout module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.EmbeddingLookUp">hetu.gpu_ops.EmbeddingLookUp module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.LayerNorm">hetu.gpu_ops.LayerNorm module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.MatrixDot">hetu.gpu_ops.MatrixDot module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.MatrixMult">hetu.gpu_ops.MatrixMult module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.MaxPool">hetu.gpu_ops.MaxPool module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.MultiplyConst">hetu.gpu_ops.MultiplyConst module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.MultiplyElewise">hetu.gpu_ops.MultiplyElewise module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Node">hetu.gpu_ops.Node module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.OneHot">hetu.gpu_ops.OneHot module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.OnesLike">hetu.gpu_ops.OnesLike module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Opposite">hetu.gpu_ops.Opposite module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Pad">hetu.gpu_ops.Pad module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.ParameterServerCommunicate">hetu.gpu_ops.ParameterServerCommunicate module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.ReduceMean">hetu.gpu_ops.ReduceMean module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.ReduceSum">hetu.gpu_ops.ReduceSum module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.ReduceSumAxisZero">hetu.gpu_ops.ReduceSumAxisZero module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Relu">hetu.gpu_ops.Relu module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Reshape">hetu.gpu_ops.Reshape module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Sigmoid">hetu.gpu_ops.Sigmoid module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Slice">hetu.gpu_ops.Slice module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Softmax">hetu.gpu_ops.Softmax module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.SoftmaxCrossEntropy">hetu.gpu_ops.SoftmaxCrossEntropy module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Sqrt">hetu.gpu_ops.Sqrt module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Tanh">hetu.gpu_ops.Tanh module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Transpose">hetu.gpu_ops.Transpose module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Variable">hetu.gpu_ops.Variable module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.Where">hetu.gpu_ops.Where module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.ZerosLike">hetu.gpu_ops.ZerosLike module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops.executor">hetu.gpu_ops.executor module</a></li>
<li><a class="reference internal" href="#module-hetu.gpu_ops">Module contents</a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Hetu</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>hetu.gpu_ops package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/hetu.gpu_ops.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="hetu-gpu-ops-package">
<h1>hetu.gpu_ops package<a class="headerlink" href="#hetu-gpu-ops-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-hetu.gpu_ops.AddConst">
<span id="hetu-gpu-ops-addconst-module"></span><h2>hetu.gpu_ops.AddConst module<a class="headerlink" href="#module-hetu.gpu_ops.AddConst" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.AddConst.AddByConstOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AddConst.</span></code><code class="sig-name descname"><span class="pre">AddByConstOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">const_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddConst.html#AddByConstOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AddConst.AddByConstOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.AddConst.AddByConstOp.compute" title="hetu.gpu_ops.AddConst.AddByConstOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.AddConst.AddByConstOp.gradient" title="hetu.gpu_ops.AddConst.AddByConstOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.AddConst.AddByConstOp.infer_shape" title="hetu.gpu_ops.AddConst.AddByConstOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.AddConst.AddByConstOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddConst.html#AddByConstOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AddConst.AddByConstOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AddConst.AddByConstOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddConst.html#AddByConstOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AddConst.AddByConstOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AddConst.AddByConstOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddConst.html#AddByConstOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AddConst.AddByConstOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.AddConst.addbyconst_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AddConst.</span></code><code class="sig-name descname"><span class="pre">addbyconst_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">const_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddConst.html#addbyconst_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AddConst.addbyconst_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a node with a constant.
Make a new instance of AddByConstOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to be added.</p>
</dd>
<dt><strong>const_val</strong><span class="classifier">scalar value</span></dt><dd><p>The constant value to be added.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.AddElewise">
<span id="hetu-gpu-ops-addelewise-module"></span><h2>hetu.gpu_ops.AddElewise module<a class="headerlink" href="#module-hetu.gpu_ops.AddElewise" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.AddElewise.AddOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AddElewise.</span></code><code class="sig-name descname"><span class="pre">AddOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddElewise.html#AddOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AddElewise.AddOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.AddElewise.AddOp.gradient" title="hetu.gpu_ops.AddElewise.AddOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.AddElewise.AddOp.infer_shape" title="hetu.gpu_ops.AddElewise.AddOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Need to handle input_vals[0].shape != input_vals[1].shape</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.AddElewise.AddOp.forward_hook">
<code class="sig-name descname"><span class="pre">forward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddElewise.html#AddOp.forward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AddElewise.AddOp.forward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AddElewise.AddOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddElewise.html#AddOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AddElewise.AddOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AddElewise.AddOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddElewise.html#AddOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AddElewise.AddOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Need to handle input_vals[0].shape != input_vals[1].shape</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.AddElewise.add_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AddElewise.</span></code><code class="sig-name descname"><span class="pre">add_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddElewise.html#add_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AddElewise.add_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a node with another.
Make a new instance of Node Addition and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node to be added.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Another Node to be added.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.AllReduceCommunicate">
<span id="hetu-gpu-ops-allreducecommunicate-module"></span><h2>hetu.gpu_ops.AllReduceCommunicate module<a class="headerlink" href="#module-hetu.gpu_ops.AllReduceCommunicate" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AllReduceCommunicate.</span></code><code class="sig-name descname"><span class="pre">AllReduceCommunicateOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nodeA</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#AllReduceCommunicateOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.compute" title="hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, comm, …])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.gradient" title="hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.infer_shape" title="hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#AllReduceCommunicateOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.forward_hook">
<code class="sig-name descname"><span class="pre">forward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#AllReduceCommunicateOp.forward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.forward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#AllReduceCommunicateOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#AllReduceCommunicateOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AllReduceCommunicate.AllReduceCommunicateOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AllReduceCommunicate.</span></code><code class="sig-name descname"><span class="pre">GroupAllReduceCommunicateOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nodeA</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_comm</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#GroupAllReduceCommunicateOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.compute" title="hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.gradient" title="hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.infer_shape" title="hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#GroupAllReduceCommunicateOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#GroupAllReduceCommunicateOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#GroupAllReduceCommunicateOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AllReduceCommunicate.GroupAllReduceCommunicateOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.AllReduceCommunicate.allreduceCommunicate_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AllReduceCommunicate.</span></code><code class="sig-name descname"><span class="pre">allreduceCommunicate_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#allreduceCommunicate_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AllReduceCommunicate.allreduceCommunicate_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce data arrays and leaves identical copies of the result on each processes.
Make a new instance of AllReduceCommunicateOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to do allreduce.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.AllReduceCommunicate.groupallreduceCommunicate_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AllReduceCommunicate.</span></code><code class="sig-name descname"><span class="pre">groupallreduceCommunicate_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_comm</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#groupallreduceCommunicate_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AllReduceCommunicate.groupallreduceCommunicate_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce data arrays and leaves identical copies of the result on each processes in group.
Make a new instance of GroupAllReduceCommunicateOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to do groupallreduce.</p>
</dd>
<dt><strong>group_comm</strong><span class="classifier">MPI_NCCL_Communicator</span></dt><dd><p>The group communicators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.AvgPool">
<span id="hetu-gpu-ops-avgpool-module"></span><h2>hetu.gpu_ops.AvgPool module<a class="headerlink" href="#module-hetu.gpu_ops.AvgPool" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.AvgPool.Avg_Pool2dOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AvgPool.</span></code><code class="sig-name descname"><span class="pre">Avg_Pool2dOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#Avg_Pool2dOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.Avg_Pool2dOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.AvgPool.Avg_Pool2dOp.compute" title="hetu.gpu_ops.AvgPool.Avg_Pool2dOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.AvgPool.Avg_Pool2dOp.gradient" title="hetu.gpu_ops.AvgPool.Avg_Pool2dOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.AvgPool.Avg_Pool2dOp.infer_shape" title="hetu.gpu_ops.AvgPool.Avg_Pool2dOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Need to handle input_vals[0].shape != input_vals[1].shape</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 69%" />
<col style="width: 31%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>np_average_pooling</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.AvgPool.Avg_Pool2dOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#Avg_Pool2dOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.Avg_Pool2dOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AvgPool.Avg_Pool2dOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#Avg_Pool2dOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.Avg_Pool2dOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AvgPool.Avg_Pool2dOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#Avg_Pool2dOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.Avg_Pool2dOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Need to handle input_vals[0].shape != input_vals[1].shape</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AvgPool.Avg_Pool2dOp.np_average_pooling">
<code class="sig-name descname"><span class="pre">np_average_pooling</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#Avg_Pool2dOp.np_average_pooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.Avg_Pool2dOp.np_average_pooling" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AvgPool.</span></code><code class="sig-name descname"><span class="pre">Avg_Pool2d_GradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_out_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#Avg_Pool2d_GradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.compute" title="hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.gradient" title="hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.infer_shape" title="hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 76%" />
<col style="width: 24%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>np_average_pooling_gradient</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#Avg_Pool2d_GradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#Avg_Pool2d_GradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#Avg_Pool2d_GradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.np_average_pooling_gradient">
<code class="sig-name descname"><span class="pre">np_average_pooling_gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradient_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#Avg_Pool2d_GradientOp.np_average_pooling_gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.Avg_Pool2d_GradientOp.np_average_pooling_gradient" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.AvgPool.avg_pool2d_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AvgPool.</span></code><code class="sig-name descname"><span class="pre">avg_pool2d_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_out_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#avg_pool2d_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.avg_pool2d_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of average pooling node.
Make a new instance of Avg_Pool2d_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_out</strong><span class="classifier">Node</span></dt><dd><p>Output node of average pooling.</p>
</dd>
<dt><strong>node_out_gradient</strong><span class="classifier">Node</span></dt><dd><p>Previous gradient node.</p>
</dd>
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input node of average pooling.</p>
</dd>
<dt><strong>kernel_H</strong><span class="classifier">Int</span></dt><dd><p>Kernel height.</p>
</dd>
<dt><strong>kernel_W</strong><span class="classifier">Int</span></dt><dd><p>Kernel width.</p>
</dd>
<dt><strong>padding</strong><span class="classifier">Int</span></dt><dd><p>Padding size.</p>
</dd>
<dt><strong>stride</strong><span class="classifier">Int</span></dt><dd><p>Stride size.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.AvgPool.avg_pool2d_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.AvgPool.</span></code><code class="sig-name descname"><span class="pre">avg_pool2d_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#avg_pool2d_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.AvgPool.avg_pool2d_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D average pooling over an input signal.
Make a new instance of Avg_Pool2dOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Input node.</p>
</dd>
<dt><strong>kernel_H</strong><span class="classifier">Int</span></dt><dd><p>Kernel height.</p>
</dd>
<dt><strong>kernel_W</strong><span class="classifier">Int</span></dt><dd><p>Kernel width.</p>
</dd>
<dt><strong>padding</strong><span class="classifier">Int</span></dt><dd><p>Padding size.</p>
</dd>
<dt><strong>stride</strong><span class="classifier">Int</span></dt><dd><p>Stride size.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.BatchMatrixMult">
<span id="hetu-gpu-ops-batchmatrixmult-module"></span><h2>hetu.gpu_ops.BatchMatrixMult module<a class="headerlink" href="#module-hetu.gpu_ops.BatchMatrixMult" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchMatrixMult.</span></code><code class="sig-name descname"><span class="pre">BatchMatMulOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_A</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_B</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchMatrixMult.html#BatchMatMulOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.compute" title="hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.gradient" title="hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.infer_shape" title="hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchMatrixMult.html#BatchMatMulOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchMatrixMult.html#BatchMatMulOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchMatrixMult.html#BatchMatMulOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchMatrixMult.BatchMatMulOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.BatchMatrixMult.batch_matmul_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchMatrixMult.</span></code><code class="sig-name descname"><span class="pre">batch_matmul_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_A</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_B</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchMatrixMult.html#batch_matmul_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchMatrixMult.batch_matmul_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiplies slices of two matrices in batches.
Make a new instance of Batch Matrix Multiplication and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The left operand of the matrix multiplication.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The right operand of the matrix multiplication.</p>
</dd>
<dt><strong>trans_A</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_A to be transposed</p>
</dd>
<dt><strong>trans_B</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_B to be transposed</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.BatchNorm">
<span id="hetu-gpu-ops-batchnorm-module"></span><h2>hetu.gpu_ops.BatchNorm module<a class="headerlink" href="#module-hetu.gpu_ops.BatchNorm" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.BatchNorm.Batch_NormalizationOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">Batch_NormalizationOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_NormalizationOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_NormalizationOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.compute" title="hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.gradient" title="hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.infer_shape" title="hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_NormalizationOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_NormalizationOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_NormalizationOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_NormalizationOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">Batch_Normalization_GradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_GradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.compute" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.gradient" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.infer_shape" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 70%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>update_mean_and_var</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_GradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_GradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_GradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.update_mean_and_var">
<code class="sig-name descname"><span class="pre">update_mean_and_var</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">saved_mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">saved_var</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_GradientOp.update_mean_and_var"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_GradientOp.update_mean_and_var" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">Batch_Normalization_Gradient_of_BiasOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bn_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_BiasOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.compute" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.gradient" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.infer_shape" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_BiasOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_BiasOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_BiasOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_BiasOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">Batch_Normalization_Gradient_of_DataOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bn_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_arr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_DataOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.compute" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.gradient" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.infer_shape" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_DataOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_DataOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_DataOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_DataOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">Batch_Normalization_Gradient_of_ScaleOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bn_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_ScaleOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.compute" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.gradient" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.infer_shape" title="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_ScaleOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_ScaleOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#Batch_Normalization_Gradient_of_ScaleOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.Batch_Normalization_Gradient_of_ScaleOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.BatchNorm.batch_normalization_gradient_of_bias_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">batch_normalization_gradient_of_bias_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bn_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batch_normalization_gradient_of_bias_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.batch_normalization_gradient_of_bias_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the bias parameter’s gradient of batch normalization node.
Make a new instance of Node Batch_Normalization_Gradient_of_ScaleOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>bn_gradient :</strong></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_bias :</strong></dt><dd><p>Bias parameter of bn layer.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.BatchNorm.batch_normalization_gradient_of_data_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">batch_normalization_gradient_of_data_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bn_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_arr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batch_normalization_gradient_of_data_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.batch_normalization_gradient_of_data_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the data’s gradient of batch normalization node.
Make a new instance of Node Batch_Normalization_Gradient_of_DataOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>bn_gradient :</strong></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_arr</strong><span class="classifier">Node</span></dt><dd><p>Input array of bn layer.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.BatchNorm.batch_normalization_gradient_of_scale_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">batch_normalization_gradient_of_scale_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bn_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batch_normalization_gradient_of_scale_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.batch_normalization_gradient_of_scale_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the scale parameter’s gradient of batch normalization node.
Make a new instance of Node Batch_Normalization_Gradient_of_ScaleOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>bn_gradient :</strong></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_scale :</strong></dt><dd><p>Scaling parameter of bn layer.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.BatchNorm.batch_normalization_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">batch_normalization_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batch_normalization_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.batch_normalization_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of batch normalization node.
Make a new instance of Node Batch_Normalization_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>out_gradient</strong><span class="classifier">Node</span></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_node</strong><span class="classifier">Node</span></dt><dd><p>Input node of bn layer.</p>
</dd>
<dt><strong>bn_scale</strong><span class="classifier">Node</span></dt><dd><p>Scaling parameter.</p>
</dd>
<dt><strong>forward_node</strong><span class="classifier">Node</span></dt><dd><p>The forward node.</p>
</dd>
<dt><strong>eps</strong><span class="classifier">float</span></dt><dd><p>Epsilon value for numerical stability.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.BatchNorm.batch_normalization_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">batch_normalization_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batch_normalization_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.batch_normalization_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalizes a matrix by mean and variance, and applies a scale to it, as well as a bias.
Make a new instance of Node Batch_NormalizationOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input data.</p>
</dd>
<dt><strong>bn_scale</strong><span class="classifier">Node</span></dt><dd><p>scaling parameter</p>
</dd>
<dt><strong>bn_bias</strong><span class="classifier">Node</span></dt><dd><p>learnable bias parameter</p>
</dd>
<dt><strong>momentum</strong><span class="classifier">float</span></dt><dd><p>Acting on the calculation of mean and variance, the mean and variance values in historical batch are retained.</p>
</dd>
<dt><strong>eps</strong><span class="classifier">float</span></dt><dd><p>Epsilon value for numerical stability.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.BatchNorm.batchnorm_backward">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">batchnorm_backward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradient_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dbn_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dbn_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_var</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batchnorm_backward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.batchnorm_backward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.BatchNorm.batchnorm_forward">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BatchNorm.</span></code><code class="sig-name descname"><span class="pre">batchnorm_forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_var</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batchnorm_forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BatchNorm.batchnorm_forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.BinaryCrossEntropy">
<span id="hetu-gpu-ops-binarycrossentropy-module"></span><h2>hetu.gpu_ops.BinaryCrossEntropy module<a class="headerlink" href="#module-hetu.gpu_ops.BinaryCrossEntropy" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BinaryCrossEntropy.</span></code><code class="sig-name descname"><span class="pre">BinaryCrossEntropyGradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_grad_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BinaryCrossEntropy.html#BinaryCrossEntropyGradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.compute" title="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.gradient" title="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.infer_shape" title="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BinaryCrossEntropy.html#BinaryCrossEntropyGradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BinaryCrossEntropy.html#BinaryCrossEntropyGradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BinaryCrossEntropy.html#BinaryCrossEntropyGradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyGradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BinaryCrossEntropy.</span></code><code class="sig-name descname"><span class="pre">BinaryCrossEntropyOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BinaryCrossEntropy.html#BinaryCrossEntropyOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.compute" title="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.gradient" title="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.infer_shape" title="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BinaryCrossEntropy.html#BinaryCrossEntropyOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BinaryCrossEntropy.html#BinaryCrossEntropyOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BinaryCrossEntropy.html#BinaryCrossEntropyOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BinaryCrossEntropy.BinaryCrossEntropyOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.BinaryCrossEntropy.binarycrossentropy_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BinaryCrossEntropy.</span></code><code class="sig-name descname"><span class="pre">binarycrossentropy_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BinaryCrossEntropy.html#binarycrossentropy_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BinaryCrossEntropy.binarycrossentropy_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of binary cross entropy node.
Make a new instance of Node BinaryCrossEntropyGradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Predicted probability.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Labels.</p>
</dd>
<dt><strong>node_C</strong><span class="classifier">Node</span></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.BinaryCrossEntropy.binarycrossentropy_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BinaryCrossEntropy.</span></code><code class="sig-name descname"><span class="pre">binarycrossentropy_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BinaryCrossEntropy.html#binarycrossentropy_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BinaryCrossEntropy.binarycrossentropy_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes cross entropy loss for pre-softmax activations.
Make a new instance of Node BinaryCrossEntropyOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Predicted probability.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Labels.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Broadcast">
<span id="hetu-gpu-ops-broadcast-module"></span><h2>hetu.gpu_ops.Broadcast module<a class="headerlink" href="#module-hetu.gpu_ops.Broadcast" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Broadcast.BroadcastToOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Broadcast.</span></code><code class="sig-name descname"><span class="pre">BroadcastToOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Broadcast.html#BroadcastToOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Broadcast.BroadcastToOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Broadcast.BroadcastToOp.compute" title="hetu.gpu_ops.Broadcast.BroadcastToOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Broadcast.BroadcastToOp.gradient" title="hetu.gpu_ops.Broadcast.BroadcastToOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Broadcast.BroadcastToOp.infer_shape" title="hetu.gpu_ops.Broadcast.BroadcastToOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Broadcast.BroadcastToOp.backward_hook">
<code class="sig-name descname"><span class="pre">backward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Broadcast.html#BroadcastToOp.backward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Broadcast.BroadcastToOp.backward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Broadcast.BroadcastToOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Broadcast.html#BroadcastToOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Broadcast.BroadcastToOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Broadcast.BroadcastToOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Broadcast.html#BroadcastToOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Broadcast.BroadcastToOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Broadcast.BroadcastToOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Broadcast.html#BroadcastToOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Broadcast.BroadcastToOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Broadcast.broadcastto_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Broadcast.</span></code><code class="sig-name descname"><span class="pre">broadcastto_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Broadcast.html#broadcastto_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Broadcast.broadcastto_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Broadcast one node’s shape to another.
Make a new instance of BroadcastToOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_a</strong><span class="classifier">Node</span></dt><dd><p>The Node to be broadcast.</p>
</dd>
<dt><strong>node_b</strong><span class="classifier">Node</span></dt><dd><p>Another Node with the target shape.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.BroadcastShape">
<span id="hetu-gpu-ops-broadcastshape-module"></span><h2>hetu.gpu_ops.BroadcastShape module<a class="headerlink" href="#module-hetu.gpu_ops.BroadcastShape" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.BroadcastShape.BroadcastShapeOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BroadcastShape.</span></code><code class="sig-name descname"><span class="pre">BroadcastShapeOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BroadcastShape.html#BroadcastShapeOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BroadcastShape.BroadcastShapeOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.compute" title="hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.gradient" title="hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.infer_shape" title="hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.backward_hook">
<code class="sig-name descname"><span class="pre">backward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BroadcastShape.html#BroadcastShapeOp.backward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.backward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BroadcastShape.html#BroadcastShapeOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BroadcastShape.html#BroadcastShapeOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BroadcastShape.html#BroadcastShapeOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BroadcastShape.BroadcastShapeOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.BroadcastShape.broadcast_shape_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.BroadcastShape.</span></code><code class="sig-name descname"><span class="pre">broadcast_shape_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BroadcastShape.html#broadcast_shape_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.BroadcastShape.broadcast_shape_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Broadcast an array to the target shape.
Make a new instance of BroadcastShapeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_a</strong><span class="classifier">Node</span></dt><dd><p>The Node to be broadcast.</p>
</dd>
<dt><strong>shape</strong><span class="classifier">tuple</span></dt><dd><p>Target shape.</p>
</dd>
<dt><strong>add_axes</strong><span class="classifier">tuple</span></dt><dd><p>The axes to be added.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Concat">
<span id="hetu-gpu-ops-concat-module"></span><h2>hetu.gpu_ops.Concat module<a class="headerlink" href="#module-hetu.gpu_ops.Concat" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Concat.ConcatOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Concat.</span></code><code class="sig-name descname"><span class="pre">ConcatOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#ConcatOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Concat.ConcatOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Concat.ConcatOp.compute" title="hetu.gpu_ops.Concat.ConcatOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Concat.ConcatOp.gradient" title="hetu.gpu_ops.Concat.ConcatOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Concat.ConcatOp.infer_shape" title="hetu.gpu_ops.Concat.ConcatOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Concat.ConcatOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#ConcatOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Concat.ConcatOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Concat.ConcatOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#ConcatOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Concat.ConcatOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Concat.ConcatOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#ConcatOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Concat.ConcatOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.Concat.Concat_gradientOP">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Concat.</span></code><code class="sig-name descname"><span class="pre">Concat_gradientOP</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#Concat_gradientOP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Concat.Concat_gradientOP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Concat.Concat_gradientOP.compute" title="hetu.gpu_ops.Concat.Concat_gradientOP.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Concat.Concat_gradientOP.gradient" title="hetu.gpu_ops.Concat.Concat_gradientOP.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Concat.Concat_gradientOP.infer_shape" title="hetu.gpu_ops.Concat.Concat_gradientOP.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Concat.Concat_gradientOP.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#Concat_gradientOP.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Concat.Concat_gradientOP.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Concat.Concat_gradientOP.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#Concat_gradientOP.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Concat.Concat_gradientOP.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Concat.Concat_gradientOP.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#Concat_gradientOP.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Concat.Concat_gradientOP.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Concat.concat_backward">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Concat.</span></code><code class="sig-name descname"><span class="pre">concat_backward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#concat_backward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Concat.concat_backward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Concat.concat_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Concat.</span></code><code class="sig-name descname"><span class="pre">concat_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#concat_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Concat.concat_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of concat node.
Make a new instance of Node Concat_gradientOP and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>grad_node</strong><span class="classifier">Node</span></dt><dd><p>Previous gradient node.</p>
</dd>
<dt><strong>input_node</strong><span class="classifier">Node</span></dt><dd><p>The node to be concatenate.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">Int</span></dt><dd><p>Axis along which to be concatenated.</p>
</dd>
<dt><strong>idx</strong><span class="classifier">Int</span></dt><dd><p>The index of concatenation.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Concat.concat_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Concat.</span></code><code class="sig-name descname"><span class="pre">concat_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#concat_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Concat.concat_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenates given variables along an axis.
Make a new instance of Node ConcatOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The first node to be concatenate.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The second node to be concatenate.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">Int</span></dt><dd><p>The axis along which two nodes are concatenate.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Conv2d">
<span id="hetu-gpu-ops-conv2d-module"></span><h2>hetu.gpu_ops.Conv2d module<a class="headerlink" href="#module-hetu.gpu_ops.Conv2d" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Conv2d.Conv2dOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Conv2d.</span></code><code class="sig-name descname"><span class="pre">Conv2dOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2dOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2dOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2d.Conv2dOp.compute" title="hetu.gpu_ops.Conv2d.Conv2dOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2d.Conv2dOp.gradient" title="hetu.gpu_ops.Conv2d.Conv2dOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2d.Conv2dOp.infer_shape" title="hetu.gpu_ops.Conv2d.Conv2dOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2d.Conv2dOp.np_conv2d" title="hetu.gpu_ops.Conv2d.Conv2dOp.np_conv2d"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np_conv2d</span></code></a>(X, Filter[, padding, stride])</p></td>
<td><p>Implement a conv2d as a matrix multiply after im2col.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>im2col</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2dOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2dOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2dOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2dOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2dOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2dOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2dOp.im2col">
<code class="sig-name descname"><span class="pre">im2col</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2dOp.im2col"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2dOp.im2col" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2dOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2dOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2dOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2dOp.np_conv2d">
<code class="sig-name descname"><span class="pre">np_conv2d</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2dOp.np_conv2d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2dOp.np_conv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Implement a conv2d as a matrix multiply after im2col.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Conv2d.</span></code><code class="sig-name descname"><span class="pre">Conv2d_Gradient_of_DataOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_DataOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.compute" title="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.gradient" title="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.infer_shape" title="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 72%" />
<col style="width: 28%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>im2col_transpose</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>np_Conv2dGradient_data</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_DataOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_DataOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.im2col_transpose">
<code class="sig-name descname"><span class="pre">im2col_transpose</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_DataOp.im2col_transpose"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.im2col_transpose" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_DataOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.np_Conv2dGradient_data">
<code class="sig-name descname"><span class="pre">np_Conv2dGradient_data</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X_N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_DataOp.np_Conv2dGradient_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_DataOp.np_Conv2dGradient_data" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Conv2d.</span></code><code class="sig-name descname"><span class="pre">Conv2d_Gradient_of_FilterOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_FilterOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.compute" title="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.gradient" title="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.infer_shape" title="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.np_Conv2dGradient_Filter" title="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.np_Conv2dGradient_Filter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np_Conv2dGradient_Filter</span></code></a>(filter_outChannel, …)</p></td>
<td><p>Implement a conv2d_transpose as a matrix multiply after im2col.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>im2col</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_FilterOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_FilterOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.im2col">
<code class="sig-name descname"><span class="pre">im2col</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_FilterOp.im2col"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.im2col" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_FilterOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.np_Conv2dGradient_Filter">
<code class="sig-name descname"><span class="pre">np_Conv2dGradient_Filter</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filter_outChannel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_inChannel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#Conv2d_Gradient_of_FilterOp.np_Conv2dGradient_Filter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.Conv2d_Gradient_of_FilterOp.np_Conv2dGradient_Filter" title="Permalink to this definition">¶</a></dt>
<dd><p>Implement a conv2d_transpose as a matrix multiply after im2col.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Conv2d.conv2d_gradient_of_data_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Conv2d.</span></code><code class="sig-name descname"><span class="pre">conv2d_gradient_of_data_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#conv2d_gradient_of_data_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.conv2d_gradient_of_data_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the data’s gradient of conv2d node.
Make a new instance of Node Conv2d_Gradient_of_DataOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Filter node.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Previous gradient node.</p>
</dd>
<dt><strong>padding</strong><span class="classifier">Int</span></dt><dd><p>Padding size.</p>
</dd>
<dt><strong>stride</strong><span class="classifier">Int</span></dt><dd><p>Stride size.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Conv2d.conv2d_gradient_of_filter_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Conv2d.</span></code><code class="sig-name descname"><span class="pre">conv2d_gradient_of_filter_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#conv2d_gradient_of_filter_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.conv2d_gradient_of_filter_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the filter’s gradient of conv2d node.
Make a new instance of Node Conv2d_Gradient_of_FilterOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>input_X</strong><span class="classifier">Node</span></dt><dd><p>Input data of conv2d.</p>
</dd>
<dt><strong>gradient_Y</strong><span class="classifier">Node</span></dt><dd><p>Gradient array.</p>
</dd>
<dt><strong>padding</strong><span class="classifier">Int</span></dt><dd><p>Padding size.</p>
</dd>
<dt><strong>stride</strong><span class="classifier">Int</span></dt><dd><p>Stride size.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Conv2d.conv2d_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Conv2d.</span></code><code class="sig-name descname"><span class="pre">conv2d_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#conv2d_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2d.conv2d_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a 2-D convolution.
Make a new instance of Node Conv2dOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Input data node.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Input filter node.</p>
</dd>
<dt><strong>padding</strong><span class="classifier">Int</span></dt><dd><p>Padding size.</p>
</dd>
<dt><strong>stride</strong><span class="classifier">Int</span></dt><dd><p>Stride size.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Conv2dBroadcast">
<span id="hetu-gpu-ops-conv2dbroadcast-module"></span><h2>hetu.gpu_ops.Conv2dBroadcast module<a class="headerlink" href="#module-hetu.gpu_ops.Conv2dBroadcast" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Conv2dBroadcast.</span></code><code class="sig-name descname"><span class="pre">Conv2d_BroadcastToOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dBroadcast.html#Conv2d_BroadcastToOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.compute" title="hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.gradient" title="hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.infer_shape" title="hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dBroadcast.html#Conv2d_BroadcastToOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dBroadcast.html#Conv2d_BroadcastToOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dBroadcast.html#Conv2d_BroadcastToOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2dBroadcast.Conv2d_BroadcastToOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Conv2dBroadcast.conv2d_broadcastto_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Conv2dBroadcast.</span></code><code class="sig-name descname"><span class="pre">conv2d_broadcastto_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dBroadcast.html#conv2d_broadcastto_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2dBroadcast.conv2d_broadcastto_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Broadcast one’s shape to another and interchange axes 1 and 3.
Make a new instance of Node Conv2d_BroadcastToOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node to be broadcast.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Another Node with the target shape.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Conv2dReduceSum">
<span id="hetu-gpu-ops-conv2dreducesum-module"></span><h2>hetu.gpu_ops.Conv2dReduceSum module<a class="headerlink" href="#module-hetu.gpu_ops.Conv2dReduceSum" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Conv2dReduceSum.</span></code><code class="sig-name descname"><span class="pre">Conv2d_ReduceSumOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dReduceSum.html#Conv2d_ReduceSumOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.compute" title="hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.gradient" title="hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.infer_shape" title="hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>summation reduction axis = 0 e.g.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dReduceSum.html#Conv2d_ReduceSumOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dReduceSum.html#Conv2d_ReduceSumOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dReduceSum.html#Conv2d_ReduceSumOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2dReduceSum.Conv2d_ReduceSumOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>summation reduction axis = 0
e.g. (3,4,5)-&gt;(4,5)
for vector, simpler to do (3,)-&gt;(1,)</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Conv2dReduceSum.conv2d_reducesum_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Conv2dReduceSum.</span></code><code class="sig-name descname"><span class="pre">conv2d_reducesum_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dReduceSum.html#conv2d_reducesum_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Conv2dReduceSum.conv2d_reducesum_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Sum of array elements over axis=(0,2,3).
Make a new instance of Node Conv2d_ReduceSumOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be summed.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.CuSparse">
<span id="hetu-gpu-ops-cusparse-module"></span><h2>hetu.gpu_ops.CuSparse module<a class="headerlink" href="#module-hetu.gpu_ops.CuSparse" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.CuSparse.CsrmmOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.CuSparse.</span></code><code class="sig-name descname"><span class="pre">CsrmmOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_A</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_B</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#CsrmmOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.CuSparse.CsrmmOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.CuSparse.CsrmmOp.compute" title="hetu.gpu_ops.CuSparse.CsrmmOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.CuSparse.CsrmmOp.gradient" title="hetu.gpu_ops.CuSparse.CsrmmOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.CuSparse.CsrmmOp.infer_shape" title="hetu.gpu_ops.CuSparse.CsrmmOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.CuSparse.CsrmmOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#CsrmmOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.CuSparse.CsrmmOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.CuSparse.CsrmmOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#CsrmmOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.CuSparse.CsrmmOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.CuSparse.CsrmmOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#CsrmmOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.CuSparse.CsrmmOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.CuSparse.CsrmvOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.CuSparse.</span></code><code class="sig-name descname"><span class="pre">CsrmvOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#CsrmvOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.CuSparse.CsrmvOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.CuSparse.CsrmvOp.compute" title="hetu.gpu_ops.CuSparse.CsrmvOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.CuSparse.CsrmvOp.gradient" title="hetu.gpu_ops.CuSparse.CsrmvOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.CuSparse.CsrmvOp.infer_shape" title="hetu.gpu_ops.CuSparse.CsrmvOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.CuSparse.CsrmvOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#CsrmvOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.CuSparse.CsrmvOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.CuSparse.CsrmvOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#CsrmvOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.CuSparse.CsrmvOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.CuSparse.CsrmvOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#CsrmvOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.CuSparse.CsrmvOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.CuSparse.csrmm_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.CuSparse.</span></code><code class="sig-name descname"><span class="pre">csrmm_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_A</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_B</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#csrmm_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.CuSparse.csrmm_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiply a sparse matrix with a dense matrix.
Make a new instance of Node CsrmmOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The left operand, a sparse matrix.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The right operand, a dense matrix.</p>
</dd>
<dt><strong>trans_A</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_A to be transposed, default to be False.</p>
</dd>
<dt><strong>trans_B</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_B to be transposed, default to be False.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.CuSparse.csrmv_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.CuSparse.</span></code><code class="sig-name descname"><span class="pre">csrmv_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#csrmv_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.CuSparse.csrmv_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiply a sparse matrix with a vector.
Make a new instance of Node CsrmvOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The left operand, a sparse matrix.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The right operand, a vector.</p>
</dd>
<dt><strong>trans</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_A to be transposed, default to be False.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.DataTransfer">
<span id="hetu-gpu-ops-datatransfer-module"></span><h2>hetu.gpu_ops.DataTransfer module<a class="headerlink" href="#module-hetu.gpu_ops.DataTransfer" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.DataTransfer.</span></code><code class="sig-name descname"><span class="pre">DataD2HOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.DataTransfer.DataD2HOp.compute" title="hetu.gpu_ops.DataTransfer.DataD2HOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.DataTransfer.DataD2HOp.gradient" title="hetu.gpu_ops.DataTransfer.DataD2HOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.DataTransfer.DataD2HOp.infer_shape" title="hetu.gpu_ops.DataTransfer.DataD2HOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HOp.backward_hook">
<code class="sig-name descname"><span class="pre">backward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HOp.backward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HOp.backward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HOp.forward_hook">
<code class="sig-name descname"><span class="pre">forward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HOp.forward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HOp.forward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HSparseOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.DataTransfer.</span></code><code class="sig-name descname"><span class="pre">DataD2HSparseOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HSparseOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HSparseOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.DataTransfer.DataD2HSparseOp.compute" title="hetu.gpu_ops.DataTransfer.DataD2HSparseOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.DataTransfer.DataD2HSparseOp.gradient" title="hetu.gpu_ops.DataTransfer.DataD2HSparseOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.DataTransfer.DataD2HSparseOp.infer_shape" title="hetu.gpu_ops.DataTransfer.DataD2HSparseOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HSparseOp.backward_hook">
<code class="sig-name descname"><span class="pre">backward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HSparseOp.backward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HSparseOp.backward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HSparseOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HSparseOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HSparseOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HSparseOp.forward_hook">
<code class="sig-name descname"><span class="pre">forward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HSparseOp.forward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HSparseOp.forward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HSparseOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HSparseOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HSparseOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataD2HSparseOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataD2HSparseOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataD2HSparseOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.DataTransfer.DataH2DOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.DataTransfer.</span></code><code class="sig-name descname"><span class="pre">DataH2DOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataH2DOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataH2DOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.DataTransfer.DataH2DOp.compute" title="hetu.gpu_ops.DataTransfer.DataH2DOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.DataTransfer.DataH2DOp.gradient" title="hetu.gpu_ops.DataTransfer.DataH2DOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.DataTransfer.DataH2DOp.infer_shape" title="hetu.gpu_ops.DataTransfer.DataH2DOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataH2DOp.backward_hook">
<code class="sig-name descname"><span class="pre">backward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataH2DOp.backward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataH2DOp.backward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataH2DOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataH2DOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataH2DOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataH2DOp.forward_hook">
<code class="sig-name descname"><span class="pre">forward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataH2DOp.forward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataH2DOp.forward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataH2DOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataH2DOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataH2DOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DataTransfer.DataH2DOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#DataH2DOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.DataH2DOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.DataTransfer.datad2h_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.DataTransfer.</span></code><code class="sig-name descname"><span class="pre">datad2h_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#datad2h_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.datad2h_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Transfer data from device(GPU) to host(CPU).
Make a new instance of Node DataD2HOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.DataTransfer.datad2h_sparse_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.DataTransfer.</span></code><code class="sig-name descname"><span class="pre">datad2h_sparse_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#datad2h_sparse_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.datad2h_sparse_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Transfer sparse data from device(GPU) to host(CPU).
Make a new instance of Node DataD2HSparseOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.DataTransfer.datah2d_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.DataTransfer.</span></code><code class="sig-name descname"><span class="pre">datah2d_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#datah2d_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DataTransfer.datah2d_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Transfer data from host(CPU) to device(GPU).
Make a new instance of Node DataH2DOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.DistGCN_15d">
<span id="hetu-gpu-ops-distgcn-15d-module"></span><h2>hetu.gpu_ops.DistGCN_15d module<a class="headerlink" href="#module-hetu.gpu_ops.DistGCN_15d" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.DistGCN_15d.</span></code><code class="sig-name descname"><span class="pre">DistGCN_15dOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_Count_Self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_Count_All</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replication</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comm_groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[None,</span> <span class="pre">None]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">need_W</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DistGCN_15d.html#DistGCN_15dOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.compute" title="hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.gradient" title="hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.infer_shape" title="hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DistGCN_15d.html#DistGCN_15dOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DistGCN_15d.html#DistGCN_15dOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DistGCN_15d.html#DistGCN_15dOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DistGCN_15d.DistGCN_15dOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.DistGCN_15d.broad_func">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.DistGCN_15d.</span></code><code class="sig-name descname"><span class="pre">broad_func</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_count</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adj_matrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replication</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">row_groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DistGCN_15d.html#broad_func"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DistGCN_15d.broad_func" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.DistGCN_15d.distgcn_15d_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.DistGCN_15d.</span></code><code class="sig-name descname"><span class="pre">distgcn_15d_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_Count_Self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_Count_All</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replication</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comm_groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[None,</span> <span class="pre">None]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">need_W</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DistGCN_15d.html#distgcn_15d_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DistGCN_15d.distgcn_15d_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of 1.5 dimension distributed graph neural network training.
Make a new instance of Node DistGCN_15dOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The adjacency matrix.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The feature matrix.</p>
</dd>
<dt><strong>node_C</strong><span class="classifier">Node</span></dt><dd><p>The weight matrix.</p>
</dd>
<dt><strong>node_Count_Self</strong><span class="classifier">Int</span></dt><dd><p>The count of nodes which current process has.</p>
</dd>
<dt><strong>node_Count_All :Int</strong></dt><dd><p>The count of total nodes.</p>
</dd>
<dt><strong>size</strong><span class="classifier">Int</span></dt><dd><p>The number of processes.</p>
</dd>
<dt><strong>replication</strong><span class="classifier">Int</span></dt><dd><p>The number of replication.</p>
</dd>
<dt><strong>device_id</strong><span class="classifier">Int</span></dt><dd><p>The device id.</p>
</dd>
<dt><strong>comm</strong><span class="classifier">MPI_NCCL_Communicator</span></dt><dd><p>The whole communicator.</p>
</dd>
<dt><strong>comm_groups</strong><span class="classifier">List</span></dt><dd><p>The list of group communicators.</p>
</dd>
<dt><strong>need_W</strong><span class="classifier">Boolean</span></dt><dd><p>Whether need weight matrix, default to be True.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.DistGCN_15d.row_num">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.DistGCN_15d.</span></code><code class="sig-name descname"><span class="pre">row_num</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_count</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DistGCN_15d.html#row_num"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.DistGCN_15d.row_num" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Division">
<span id="hetu-gpu-ops-division-module"></span><h2>hetu.gpu_ops.Division module<a class="headerlink" href="#module-hetu.gpu_ops.Division" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Division.DivConstOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Division.</span></code><code class="sig-name descname"><span class="pre">DivConstOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">const_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#DivConstOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Division.DivConstOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Division.DivConstOp.compute" title="hetu.gpu_ops.Division.DivConstOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Division.DivConstOp.gradient" title="hetu.gpu_ops.Division.DivConstOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Division.DivConstOp.infer_shape" title="hetu.gpu_ops.Division.DivConstOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Division.DivConstOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#DivConstOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Division.DivConstOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Division.DivConstOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#DivConstOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Division.DivConstOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Division.DivConstOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#DivConstOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Division.DivConstOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.Division.DivOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Division.</span></code><code class="sig-name descname"><span class="pre">DivOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#DivOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Division.DivOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Division.DivOp.compute" title="hetu.gpu_ops.Division.DivOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Division.DivOp.gradient" title="hetu.gpu_ops.Division.DivOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Division.DivOp.infer_shape" title="hetu.gpu_ops.Division.DivOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Division.DivOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#DivOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Division.DivOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Division.DivOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#DivOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Division.DivOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Division.DivOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#DivOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Division.DivOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Division.div_const_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Division.</span></code><code class="sig-name descname"><span class="pre">div_const_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">const_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#div_const_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Division.div_const_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Divide a matrix by a constant.
Make a new instance of Node DivConstOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>const_val: scalar value</strong></dt><dd><p>The constant value to be multiplied.</p>
</dd>
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node where elements are denominators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Division.div_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Division.</span></code><code class="sig-name descname"><span class="pre">div_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#div_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Division.div_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Divide a matrix with another matrix.
Make a new instance of Node DivOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node where elements are numerators.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Another Node where elements are denominators.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Dropout">
<span id="hetu-gpu-ops-dropout-module"></span><h2>hetu.gpu_ops.Dropout module<a class="headerlink" href="#module-hetu.gpu_ops.Dropout" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Dropout.DropoutOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Dropout.</span></code><code class="sig-name descname"><span class="pre">DropoutOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_prob</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#DropoutOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.DropoutOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Dropout.DropoutOp.compute" title="hetu.gpu_ops.Dropout.DropoutOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Dropout.DropoutOp.gradient" title="hetu.gpu_ops.Dropout.DropoutOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Dropout.DropoutOp.infer_shape" title="hetu.gpu_ops.Dropout.DropoutOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Dropout.DropoutOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#DropoutOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.DropoutOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Dropout.DropoutOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#DropoutOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.DropoutOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Dropout.DropoutOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#DropoutOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.DropoutOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.Dropout.Dropout_GradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Dropout.</span></code><code class="sig-name descname"><span class="pre">Dropout_GradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_prob</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#Dropout_GradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.Dropout_GradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Dropout.Dropout_GradientOp.compute" title="hetu.gpu_ops.Dropout.Dropout_GradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Dropout.Dropout_GradientOp.gradient" title="hetu.gpu_ops.Dropout.Dropout_GradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Dropout.Dropout_GradientOp.infer_shape" title="hetu.gpu_ops.Dropout.Dropout_GradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Dropout.Dropout_GradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#Dropout_GradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.Dropout_GradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Dropout.Dropout_GradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#Dropout_GradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.Dropout_GradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Dropout.Dropout_GradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#Dropout_GradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.Dropout_GradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Dropout.dropout_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Dropout.</span></code><code class="sig-name descname"><span class="pre">dropout_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_prob</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#dropout_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.dropout_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of drop out node.
Make a new instance of Node Dropout_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>keep_prob</strong><span class="classifier">float</span></dt><dd><p>Probability of the results to be kept.</p>
</dd>
<dt><strong>forward_node</strong><span class="classifier">Node</span></dt><dd><p>The forward node .</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Dropout.dropout_np">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Dropout.</span></code><code class="sig-name descname"><span class="pre">dropout_np</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_prob</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_arr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#dropout_np"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.dropout_np" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Dropout.dropout_np_gradient">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Dropout.</span></code><code class="sig-name descname"><span class="pre">dropout_np_gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_gradient_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_prob</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#dropout_np_gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.dropout_np_gradient" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Dropout.dropout_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Dropout.</span></code><code class="sig-name descname"><span class="pre">dropout_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_prob</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#dropout_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Dropout.dropout_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Drop elements of input variable randomly.
Make a new instance of Node DropoutOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>keep_prob</strong><span class="classifier">float</span></dt><dd><p>Probability of the results to be kept.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.EmbeddingLookUp">
<span id="hetu-gpu-ops-embeddinglookup-module"></span><h2>hetu.gpu_ops.EmbeddingLookUp module<a class="headerlink" href="#module-hetu.gpu_ops.EmbeddingLookUp" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.EmbeddingLookUp.</span></code><code class="sig-name descname"><span class="pre">EmbeddingLookUp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#EmbeddingLookUp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.gradient" title="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.infer_shape" title="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.backward_hook">
<code class="sig-name descname"><span class="pre">backward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#EmbeddingLookUp.backward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.backward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.forward_hook">
<code class="sig-name descname"><span class="pre">forward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#EmbeddingLookUp.forward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.forward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#EmbeddingLookUp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#EmbeddingLookUp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.EmbeddingLookUp.</span></code><code class="sig-name descname"><span class="pre">EmbeddingLookUp_Gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vectors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#EmbeddingLookUp_Gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.compute" title="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.gradient" title="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.infer_shape" title="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.backward_hook">
<code class="sig-name descname"><span class="pre">backward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#EmbeddingLookUp_Gradient.backward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.backward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#EmbeddingLookUp_Gradient.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#EmbeddingLookUp_Gradient.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#EmbeddingLookUp_Gradient.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.EmbeddingLookUp_Gradient.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.EmbeddingLookUp.embedding_lookup_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.EmbeddingLookUp.</span></code><code class="sig-name descname"><span class="pre">embedding_lookup_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vectors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#embedding_lookup_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.embedding_lookup_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of embedding lookUp node.
Make a new instance of EmbeddingLookUp_Gradient and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>vectors</strong><span class="classifier">Node</span></dt><dd><p>Vectors which looked up from Embedding.</p>
</dd>
<dt><strong>index</strong><span class="classifier">Node</span></dt><dd><p>The index to be looked up.</p>
</dd>
<dt><strong>embed_shape</strong><span class="classifier">tuple</span></dt><dd><p>The shape of embedding.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.EmbeddingLookUp.embedding_lookup_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.EmbeddingLookUp.</span></code><code class="sig-name descname"><span class="pre">embedding_lookup_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#embedding_lookup_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.EmbeddingLookUp.embedding_lookup_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Find a vector in the embedding table according to specified index.
Make a new instance of EmbeddingLookUp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>embedding</strong><span class="classifier">Node</span></dt><dd><p>The Node of Embedding.</p>
</dd>
<dt><strong>index</strong><span class="classifier">Node</span></dt><dd><p>The index to be looked up.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.LayerNorm">
<span id="hetu-gpu-ops-layernorm-module"></span><h2>hetu.gpu_ops.LayerNorm module<a class="headerlink" href="#module-hetu.gpu_ops.LayerNorm" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.LayerNorm.Layer_NormalizationOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.LayerNorm.</span></code><code class="sig-name descname"><span class="pre">Layer_NormalizationOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ln_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ln_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_NormalizationOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_NormalizationOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.compute" title="hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.gradient" title="hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.infer_shape" title="hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_NormalizationOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_NormalizationOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_NormalizationOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_NormalizationOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.LayerNorm.</span></code><code class="sig-name descname"><span class="pre">Layer_Normalization_GradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ln_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_GradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.compute" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.gradient" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.infer_shape" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_GradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_GradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_GradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_GradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.LayerNorm.</span></code><code class="sig-name descname"><span class="pre">Layer_Normalization_Gradient_of_BiasOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ln_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_BiasOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.compute" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.gradient" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.infer_shape" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_BiasOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_BiasOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_BiasOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_BiasOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.LayerNorm.</span></code><code class="sig-name descname"><span class="pre">Layer_Normalization_Gradient_of_DataOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ln_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_arr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_DataOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.compute" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.gradient" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.infer_shape" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_DataOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_DataOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_DataOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_DataOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.LayerNorm.</span></code><code class="sig-name descname"><span class="pre">Layer_Normalization_Gradient_of_ScaleOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ln_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_ScaleOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.compute" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.gradient" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.infer_shape" title="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_ScaleOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_ScaleOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#Layer_Normalization_Gradient_of_ScaleOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.Layer_Normalization_Gradient_of_ScaleOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.LayerNorm.layer_normalization_gradient_of_bias_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.LayerNorm.</span></code><code class="sig-name descname"><span class="pre">layer_normalization_gradient_of_bias_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ln_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#layer_normalization_gradient_of_bias_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.layer_normalization_gradient_of_bias_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the bias parameter’s gradient of layer normalization node.
Make a new instance of Node Layer_Normalization_Gradient_of_ScaleOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>ln_gradient :</strong></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_bias :</strong></dt><dd><p>Bias parameter of ln layer.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.LayerNorm.layer_normalization_gradient_of_data_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.LayerNorm.</span></code><code class="sig-name descname"><span class="pre">layer_normalization_gradient_of_data_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ln_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_arr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#layer_normalization_gradient_of_data_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.layer_normalization_gradient_of_data_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the data’s gradient of layer normalization node.
Make a new instance of Node Layer_Normalization_Gradient_of_DataOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>ln_gradient</strong><span class="classifier">Node</span></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_arr</strong><span class="classifier">Node</span></dt><dd><p>Input array of ln layer.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.LayerNorm.layer_normalization_gradient_of_scale_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.LayerNorm.</span></code><code class="sig-name descname"><span class="pre">layer_normalization_gradient_of_scale_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ln_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#layer_normalization_gradient_of_scale_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.layer_normalization_gradient_of_scale_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the scale parameter’s gradient of layer normalization node.
Make a new instance of Node Layer_Normalization_Gradient_of_ScaleOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>ln_gradient</strong><span class="classifier">Node</span></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_scale</strong><span class="classifier">Node</span></dt><dd><p>Scaling parameter of ln layer.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.LayerNorm.layer_normalization_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.LayerNorm.</span></code><code class="sig-name descname"><span class="pre">layer_normalization_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ln_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#layer_normalization_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.layer_normalization_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of layer normalization node.
Make a new instance of Node Layer_Normalization_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>out_gradient :</strong></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_node</strong><span class="classifier">Node</span></dt><dd><p>Input node of ln layer.</p>
</dd>
<dt><strong>ln_scale :</strong></dt><dd><p>Scaling parameter.</p>
</dd>
<dt><strong>forward_node</strong><span class="classifier">Node</span></dt><dd><p>The forward node.</p>
</dd>
<dt><strong>eps</strong><span class="classifier">float</span></dt><dd><p>Epsilon value for numerical stability.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.LayerNorm.layer_normalization_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.LayerNorm.</span></code><code class="sig-name descname"><span class="pre">layer_normalization_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ln_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ln_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#layer_normalization_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.LayerNorm.layer_normalization_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Layer normalization.
Make a new instance of Node Layer_NormalizationOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input data.</p>
</dd>
<dt><strong>ln_scale</strong><span class="classifier">float</span></dt><dd><p>scaling parameter</p>
</dd>
<dt><strong>ln_bias</strong><span class="classifier">float</span></dt><dd><p>learnable bias parameter</p>
</dd>
<dt><strong>eps</strong><span class="classifier">float</span></dt><dd><p>Epsilon value for numerical stability.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.MatrixDot">
<span id="hetu-gpu-ops-matrixdot-module"></span><h2>hetu.gpu_ops.MatrixDot module<a class="headerlink" href="#module-hetu.gpu_ops.MatrixDot" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.MatrixDot.MatrixDotOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MatrixDot.</span></code><code class="sig-name descname"><span class="pre">MatrixDotOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixDot.html#MatrixDotOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MatrixDot.MatrixDotOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MatrixDot.MatrixDotOp.compute" title="hetu.gpu_ops.MatrixDot.MatrixDotOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.MatrixDot.MatrixDotOp.gradient" title="hetu.gpu_ops.MatrixDot.MatrixDotOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MatrixDot.MatrixDotOp.infer_shape" title="hetu.gpu_ops.MatrixDot.MatrixDotOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Need to handle input_vals[0].shape != input_vals[1].shape</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.MatrixDot.MatrixDotOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixDot.html#MatrixDotOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MatrixDot.MatrixDotOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MatrixDot.MatrixDotOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixDot.html#MatrixDotOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MatrixDot.MatrixDotOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MatrixDot.MatrixDotOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixDot.html#MatrixDotOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MatrixDot.MatrixDotOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Need to handle input_vals[0].shape != input_vals[1].shape</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.MatrixDot.matrix_dot_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MatrixDot.</span></code><code class="sig-name descname"><span class="pre">matrix_dot_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixDot.html#matrix_dot_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MatrixDot.matrix_dot_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the elementwise multiplication of two matrixs.
Make a new instance of MatrixDotOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_a</strong><span class="classifier">Node</span></dt><dd><p>The Node to be multiplied.</p>
</dd>
<dt><strong>node_b</strong><span class="classifier">Node</span></dt><dd><p>Another Node to be multiplied.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by MatrixDotOp.</dt><dd><p>Return the elementwise multiplication of two matrixs.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.MatrixMult">
<span id="hetu-gpu-ops-matrixmult-module"></span><h2>hetu.gpu_ops.MatrixMult module<a class="headerlink" href="#module-hetu.gpu_ops.MatrixMult" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.MatrixMult.MatMulOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MatrixMult.</span></code><code class="sig-name descname"><span class="pre">MatMulOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_A</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_B</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixMult.html#MatMulOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MatrixMult.MatMulOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MatrixMult.MatMulOp.compute" title="hetu.gpu_ops.MatrixMult.MatMulOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.MatrixMult.MatMulOp.gradient" title="hetu.gpu_ops.MatrixMult.MatMulOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MatrixMult.MatMulOp.infer_shape" title="hetu.gpu_ops.MatrixMult.MatMulOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.MatrixMult.MatMulOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixMult.html#MatMulOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MatrixMult.MatMulOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MatrixMult.MatMulOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixMult.html#MatMulOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MatrixMult.MatMulOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MatrixMult.MatMulOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixMult.html#MatMulOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MatrixMult.MatMulOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.MatrixMult.matmul_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MatrixMult.</span></code><code class="sig-name descname"><span class="pre">matmul_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_A</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_B</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixMult.html#matmul_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MatrixMult.matmul_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiply a matrix with another.
Make a new instance of Node MatMulOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The left operand of the matrix multiplication.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The right operand of the matrix multiplication.</p>
</dd>
<dt><strong>trans_A</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_A to be transposed, default to be False.</p>
</dd>
<dt><strong>trans_B</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_B to be transposed, default to be False.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.MaxPool">
<span id="hetu-gpu-ops-maxpool-module"></span><h2>hetu.gpu_ops.MaxPool module<a class="headerlink" href="#module-hetu.gpu_ops.MaxPool" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.MaxPool.Max_Pool2dOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MaxPool.</span></code><code class="sig-name descname"><span class="pre">Max_Pool2dOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#Max_Pool2dOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.Max_Pool2dOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MaxPool.Max_Pool2dOp.compute" title="hetu.gpu_ops.MaxPool.Max_Pool2dOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.MaxPool.Max_Pool2dOp.gradient" title="hetu.gpu_ops.MaxPool.Max_Pool2dOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MaxPool.Max_Pool2dOp.infer_shape" title="hetu.gpu_ops.MaxPool.Max_Pool2dOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Need to handle input_vals[0].shape != input_vals[1].shape</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.MaxPool.Max_Pool2dOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#Max_Pool2dOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.Max_Pool2dOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MaxPool.Max_Pool2dOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#Max_Pool2dOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.Max_Pool2dOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MaxPool.Max_Pool2dOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#Max_Pool2dOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.Max_Pool2dOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Need to handle input_vals[0].shape != input_vals[1].shape</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MaxPool.</span></code><code class="sig-name descname"><span class="pre">Max_Pool2d_GradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_out_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#Max_Pool2d_GradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.compute" title="hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.gradient" title="hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.infer_shape" title="hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#Max_Pool2d_GradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#Max_Pool2d_GradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#Max_Pool2d_GradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.Max_Pool2d_GradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.MaxPool.max_pool2d_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MaxPool.</span></code><code class="sig-name descname"><span class="pre">max_pool2d_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_out_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#max_pool2d_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.max_pool2d_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of max pooling node.
Make a new instance of Max_Pool2d_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_out</strong><span class="classifier">Node</span></dt><dd><p>Output Node</p>
</dd>
<dt><strong>node_out_gradient</strong><span class="classifier">Node</span></dt><dd><p>Gradient array</p>
</dd>
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input Node</p>
</dd>
<dt><strong>kernel_H</strong><span class="classifier">scalar value</span></dt><dd><p>Size of pool(height)</p>
</dd>
<dt><strong>kernel_W</strong><span class="classifier">scalar value</span></dt><dd><p>Size of pool(width)</p>
</dd>
<dt><strong>padding</strong><span class="classifier">scalar value</span></dt><dd><p>Padding edge</p>
</dd>
<dt><strong>stride</strong><span class="classifier">scalar value</span></dt><dd><p>Step Length of the kernel</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.MaxPool.max_pool2d_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MaxPool.</span></code><code class="sig-name descname"><span class="pre">max_pool2d_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#max_pool2d_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.max_pool2d_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform the max pooling on the input node.
Make a new instance of Max_Pool2dOp and call the instance.</p>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.MaxPool.np_max_pooling">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MaxPool.</span></code><code class="sig-name descname"><span class="pre">np_max_pooling</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#np_max_pooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.np_max_pooling" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.MaxPool.np_max_pooling_gradient">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MaxPool.</span></code><code class="sig-name descname"><span class="pre">np_max_pooling_gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#np_max_pooling_gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MaxPool.np_max_pooling_gradient" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.MultiplyConst">
<span id="hetu-gpu-ops-multiplyconst-module"></span><h2>hetu.gpu_ops.MultiplyConst module<a class="headerlink" href="#module-hetu.gpu_ops.MultiplyConst" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.MultiplyConst.MulByConstOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MultiplyConst.</span></code><code class="sig-name descname"><span class="pre">MulByConstOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">const_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyConst.html#MulByConstOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MultiplyConst.MulByConstOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MultiplyConst.MulByConstOp.compute" title="hetu.gpu_ops.MultiplyConst.MulByConstOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.MultiplyConst.MulByConstOp.gradient" title="hetu.gpu_ops.MultiplyConst.MulByConstOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MultiplyConst.MulByConstOp.infer_shape" title="hetu.gpu_ops.MultiplyConst.MulByConstOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.MultiplyConst.MulByConstOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyConst.html#MulByConstOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MultiplyConst.MulByConstOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MultiplyConst.MulByConstOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyConst.html#MulByConstOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MultiplyConst.MulByConstOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MultiplyConst.MulByConstOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyConst.html#MulByConstOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MultiplyConst.MulByConstOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.MultiplyConst.mul_byconst_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MultiplyConst.</span></code><code class="sig-name descname"><span class="pre">mul_byconst_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">const_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyConst.html#mul_byconst_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MultiplyConst.mul_byconst_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the multiplication of a matrix and a const value.
Make a new instance of MulByConstOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to be multiplied.</p>
</dd>
<dt><strong>const_val</strong><span class="classifier">scalar value</span></dt><dd><p>The constant value to be mutiplied.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by MulByConstOp.</dt><dd><p>Return the elementwise multiplication of an node and a const value.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.MultiplyElewise">
<span id="hetu-gpu-ops-multiplyelewise-module"></span><h2>hetu.gpu_ops.MultiplyElewise module<a class="headerlink" href="#module-hetu.gpu_ops.MultiplyElewise" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.MultiplyElewise.MulOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MultiplyElewise.</span></code><code class="sig-name descname"><span class="pre">MulOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyElewise.html#MulOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MultiplyElewise.MulOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MultiplyElewise.MulOp.compute" title="hetu.gpu_ops.MultiplyElewise.MulOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.MultiplyElewise.MulOp.gradient" title="hetu.gpu_ops.MultiplyElewise.MulOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.MultiplyElewise.MulOp.infer_shape" title="hetu.gpu_ops.MultiplyElewise.MulOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Need to handle input_vals[0].shape != input_vals[1].shape</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.MultiplyElewise.MulOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyElewise.html#MulOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MultiplyElewise.MulOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MultiplyElewise.MulOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyElewise.html#MulOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MultiplyElewise.MulOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.MultiplyElewise.MulOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyElewise.html#MulOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MultiplyElewise.MulOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Need to handle input_vals[0].shape != input_vals[1].shape</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.MultiplyElewise.mul_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.MultiplyElewise.</span></code><code class="sig-name descname"><span class="pre">mul_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyElewise.html#mul_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.MultiplyElewise.mul_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the elementwise multiplication of two arrays.
Make a new instance of MulOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_a</strong><span class="classifier">Node</span></dt><dd><p>The Node to be multiplied.</p>
</dd>
<dt><strong>node_b</strong><span class="classifier">Node</span></dt><dd><p>Another Node to be multiplied.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by MulOp.</dt><dd><p>Return the elementwise multiplication of two arrays.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Node">
<span id="hetu-gpu-ops-node-module"></span><h2>hetu.gpu_ops.Node module<a class="headerlink" href="#module-hetu.gpu_ops.Node" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Node.Op">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Node.</span></code><code class="sig-name descname"><span class="pre">Op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">op_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Node.html#Op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Node.Op" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Node in a computation graph.</p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Node.Op.compute" title="hetu.gpu_ops.Node.Op.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Node.Op.gradient" title="hetu.gpu_ops.Node.Op.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Node.Op.infer_shape" title="hetu.gpu_ops.Node.Op.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Node.Op.add_transfer_op">
<code class="sig-name descname"><span class="pre">add_transfer_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dst_ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h2d_ops</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">d2h_ops</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Node.html#Op.add_transfer_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Node.Op.add_transfer_op" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Node.Op.backward_hook">
<code class="sig-name descname"><span class="pre">backward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Node.html#Op.backward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Node.Op.backward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Node.Op.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Node.html#Op.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Node.Op.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Node.Op.forward_hook">
<code class="sig-name descname"><span class="pre">forward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Node.html#Op.forward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Node.Op.forward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Node.Op.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Node.html#Op.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Node.Op.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Node.Op.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Node.html#Op.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Node.Op.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.OneHot">
<span id="hetu-gpu-ops-onehot-module"></span><h2>hetu.gpu_ops.OneHot module<a class="headerlink" href="#module-hetu.gpu_ops.OneHot" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.OneHot.OneHotOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.OneHot.</span></code><code class="sig-name descname"><span class="pre">OneHotOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OneHot.html#OneHotOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.OneHot.OneHotOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.OneHot.OneHotOp.compute" title="hetu.gpu_ops.OneHot.OneHotOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.OneHot.OneHotOp.gradient" title="hetu.gpu_ops.OneHot.OneHotOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.OneHot.OneHotOp.infer_shape" title="hetu.gpu_ops.OneHot.OneHotOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.OneHot.OneHotOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OneHot.html#OneHotOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.OneHot.OneHotOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.OneHot.OneHotOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OneHot.html#OneHotOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.OneHot.OneHotOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.OneHot.OneHotOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OneHot.html#OneHotOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.OneHot.OneHotOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.OneHot.one_hot_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.OneHot.</span></code><code class="sig-name descname"><span class="pre">one_hot_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OneHot.html#one_hot_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.OneHot.one_hot_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents one hot.
Make a new instance of OneHotOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The input Node.</p>
</dd>
<dt><strong>num_classes: int</strong></dt><dd><p>Number of classes.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by OneHotOp.</dt><dd><p>Return the one hot representation of the input node.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.OnesLike">
<span id="hetu-gpu-ops-oneslike-module"></span><h2>hetu.gpu_ops.OnesLike module<a class="headerlink" href="#module-hetu.gpu_ops.OnesLike" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.OnesLike.OnesLikeOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.OnesLike.</span></code><code class="sig-name descname"><span class="pre">OnesLikeOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OnesLike.html#OnesLikeOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.OnesLike.OnesLikeOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.OnesLike.OnesLikeOp.compute" title="hetu.gpu_ops.OnesLike.OnesLikeOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.OnesLike.OnesLikeOp.gradient" title="hetu.gpu_ops.OnesLike.OnesLikeOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.OnesLike.OnesLikeOp.infer_shape" title="hetu.gpu_ops.OnesLike.OnesLikeOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>If input_shape is a vector, simpler to return (1,)</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.OnesLike.OnesLikeOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OnesLike.html#OnesLikeOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.OnesLike.OnesLikeOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.OnesLike.OnesLikeOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OnesLike.html#OnesLikeOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.OnesLike.OnesLikeOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.OnesLike.OnesLikeOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OnesLike.html#OnesLikeOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.OnesLike.OnesLikeOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>If input_shape is a vector, simpler to return (1,)</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.OnesLike.oneslike_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.OnesLike.</span></code><code class="sig-name descname"><span class="pre">oneslike_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OnesLike.html#oneslike_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.OnesLike.oneslike_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.ones(node_A.shape); Return a new array of given shape and type, filled with ones.
Make a new instance of OnesLikeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to pad with 1.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by OnesLikeOp.</dt><dd><p>Return a new array of ones with given shape, dtype, and order.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Opposite">
<span id="hetu-gpu-ops-opposite-module"></span><h2>hetu.gpu_ops.Opposite module<a class="headerlink" href="#module-hetu.gpu_ops.Opposite" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Opposite.OppositeOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Opposite.</span></code><code class="sig-name descname"><span class="pre">OppositeOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Opposite.html#OppositeOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Opposite.OppositeOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Opposite.OppositeOp.compute" title="hetu.gpu_ops.Opposite.OppositeOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Opposite.OppositeOp.gradient" title="hetu.gpu_ops.Opposite.OppositeOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Opposite.OppositeOp.infer_shape" title="hetu.gpu_ops.Opposite.OppositeOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Opposite.OppositeOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Opposite.html#OppositeOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Opposite.OppositeOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Opposite.OppositeOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Opposite.html#OppositeOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Opposite.OppositeOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Opposite.OppositeOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Opposite.html#OppositeOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Opposite.OppositeOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Opposite.opposite_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Opposite.</span></code><code class="sig-name descname"><span class="pre">opposite_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Opposite.html#opposite_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Opposite.opposite_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the opposite of a matrix elementwisely.
Make a new instance of OppositeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by OppositeOp.</dt><dd><p>Return the opposite of a matrix node elementwisely.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Pad">
<span id="hetu-gpu-ops-pad-module"></span><h2>hetu.gpu_ops.Pad module<a class="headerlink" href="#module-hetu.gpu_ops.Pad" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Pad.PadOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Pad.</span></code><code class="sig-name descname"><span class="pre">PadOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'CONSTANT'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constant_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#PadOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.PadOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Pad.PadOp.compute" title="hetu.gpu_ops.Pad.PadOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Pad.PadOp.gradient" title="hetu.gpu_ops.Pad.PadOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Pad.PadOp.infer_shape" title="hetu.gpu_ops.Pad.PadOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Pad.PadOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#PadOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.PadOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Pad.PadOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#PadOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.PadOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Pad.PadOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#PadOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.PadOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.Pad.Pad_GradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Pad.</span></code><code class="sig-name descname"><span class="pre">Pad_GradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'CONSTANT'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#Pad_GradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.Pad_GradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Pad.Pad_GradientOp.compute" title="hetu.gpu_ops.Pad.Pad_GradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Pad.Pad_GradientOp.gradient" title="hetu.gpu_ops.Pad.Pad_GradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Pad.Pad_GradientOp.infer_shape" title="hetu.gpu_ops.Pad.Pad_GradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Pad.Pad_GradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#Pad_GradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.Pad_GradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Pad.Pad_GradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#Pad_GradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.Pad_GradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Pad.Pad_GradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#Pad_GradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.Pad_GradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Pad.pad_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Pad.</span></code><code class="sig-name descname"><span class="pre">pad_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'CONSTANT'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#pad_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.pad_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents the gradients of np.pad.
Make a new instance of Pad_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node to be padded.</p>
</dd>
<dt><strong>paddings</strong><span class="classifier">Node</span></dt><dd><p>Number of values padded to the edges of each axis.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">str, optional, default: CONSTANT</span></dt><dd><p>Padding mode: CONSTANT/REFLECT/SYMMETRIC</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Pad_GradientOp.</dt><dd><p>Return the gradient of padding operation.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Pad.pad_np">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Pad.</span></code><code class="sig-name descname"><span class="pre">pad_np</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'constant'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constant_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#pad_np"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.pad_np" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Pad.pad_np_gradient">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Pad.</span></code><code class="sig-name descname"><span class="pre">pad_np_gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paddings</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#pad_np_gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.pad_np_gradient" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Pad.pad_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Pad.</span></code><code class="sig-name descname"><span class="pre">pad_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'CONSTANT'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constant_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#pad_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Pad.pad_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.pad; pad an input variable.
Make a new instance of PadOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node to be padded.</p>
</dd>
<dt><strong>paddings</strong><span class="classifier">Node</span></dt><dd><p>Number of values padded to the edges of each axis.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">str, optional, default: CONSTANT</span></dt><dd><p>Padding mode: CONSTANT/REFLECT/SYMMETRIC</p>
</dd>
<dt><strong>constant_values: scalar value, optional, default: 0</strong></dt><dd><p>Padding values.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by PadOp.</dt><dd><p>Return the padded array node.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.ParameterServerCommunicate">
<span id="hetu-gpu-ops-parameterservercommunicate-module"></span><h2>hetu.gpu_ops.ParameterServerCommunicate module<a class="headerlink" href="#module-hetu.gpu_ops.ParameterServerCommunicate" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ParameterServerCommunicate.</span></code><code class="sig-name descname"><span class="pre">ParameterServerCommunicateOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nodeA</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#ParameterServerCommunicateOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp.gradient" title="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp.infer_shape" title="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp.forward_hook">
<code class="sig-name descname"><span class="pre">forward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#ParameterServerCommunicateOp.forward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp.forward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#ParameterServerCommunicateOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#ParameterServerCommunicateOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerCommunicateOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ParameterServerCommunicate.</span></code><code class="sig-name descname"><span class="pre">ParameterServerSparsePullOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deps_node</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#ParameterServerSparsePullOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.compute" title="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.gradient" title="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.infer_shape" title="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#ParameterServerSparsePullOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.forward_hook">
<code class="sig-name descname"><span class="pre">forward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#ParameterServerSparsePullOp.forward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.forward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#ParameterServerSparsePullOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#ParameterServerSparsePullOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ParameterServerCommunicate.ParameterServerSparsePullOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.ParameterServerCommunicate.parameterServerCommunicate_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ParameterServerCommunicate.</span></code><code class="sig-name descname"><span class="pre">parameterServerCommunicate_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#parameterServerCommunicate_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ParameterServerCommunicate.parameterServerCommunicate_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a node for the communication with parameter server.
Make a new instance of ParameterServerCommunicateOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to do allreduce.</p>
</dd>
<dt><strong>parameter: Node</strong></dt><dd><p>The parameter Node that corresponding to the gradient.</p>
</dd>
<dt><strong>optimizer: Optimizer object</strong></dt><dd><p>The optimizer to use.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ParameterServerCommunicateOp.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.ParameterServerCommunicate.parameterServerSparsePull_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ParameterServerCommunicate.</span></code><code class="sig-name descname"><span class="pre">parameterServerSparsePull_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deps_node</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#parameterServerSparsePull_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ParameterServerCommunicate.parameterServerSparsePull_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a node for the Sparse Pull communication with parameter server.
Make a new instance of ParameterServerCommunicateOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>parameter: Node</strong></dt><dd><p>The parameter Node that corresponding to the gradient.</p>
</dd>
<dt><strong>deps_node</strong><span class="classifier">Node</span></dt><dd><p>The Node to do Pull data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ParameterServerSparsePullOp.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.ReduceMean">
<span id="hetu-gpu-ops-reducemean-module"></span><h2>hetu.gpu_ops.ReduceMean module<a class="headerlink" href="#module-hetu.gpu_ops.ReduceMean" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.ReduceMean.ReduceMeanOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ReduceMean.</span></code><code class="sig-name descname"><span class="pre">ReduceMeanOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceMean.html#ReduceMeanOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceMean.ReduceMeanOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.ReduceMean.ReduceMeanOp.compute" title="hetu.gpu_ops.ReduceMean.ReduceMeanOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.ReduceMean.ReduceMeanOp.gradient" title="hetu.gpu_ops.ReduceMean.ReduceMeanOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.ReduceMean.ReduceMeanOp.infer_shape" title="hetu.gpu_ops.ReduceMean.ReduceMeanOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.ReduceMean.ReduceMeanOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceMean.html#ReduceMeanOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceMean.ReduceMeanOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ReduceMean.ReduceMeanOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceMean.html#ReduceMeanOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceMean.ReduceMeanOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ReduceMean.ReduceMeanOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceMean.html#ReduceMeanOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceMean.ReduceMeanOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.ReduceMean.reduce_mean_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ReduceMean.</span></code><code class="sig-name descname"><span class="pre">reduce_mean_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceMean.html#reduce_mean_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceMean.reduce_mean_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.mean(node_A, axis, keepdims); Average of array elements over a given axis.
Make a new instance of ReduceMeanOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be averaged.</p>
</dd>
<dt><strong>axes</strong><span class="classifier">int or list</span></dt><dd><p>The axis/axes needed to be averaged.</p>
</dd>
<dt><strong>keepdims: bool or list</strong></dt><dd><p>Whether to keep the dimension(s).</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ReduceMeanOp.</dt><dd><p>Return the average of array elements over a given axis.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.ReduceSum">
<span id="hetu-gpu-ops-reducesum-module"></span><h2>hetu.gpu_ops.ReduceSum module<a class="headerlink" href="#module-hetu.gpu_ops.ReduceSum" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.ReduceSum.ReduceSumOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ReduceSum.</span></code><code class="sig-name descname"><span class="pre">ReduceSumOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSum.html#ReduceSumOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceSum.ReduceSumOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.ReduceSum.ReduceSumOp.compute" title="hetu.gpu_ops.ReduceSum.ReduceSumOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.ReduceSum.ReduceSumOp.gradient" title="hetu.gpu_ops.ReduceSum.ReduceSumOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.ReduceSum.ReduceSumOp.infer_shape" title="hetu.gpu_ops.ReduceSum.ReduceSumOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.ReduceSum.ReduceSumOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSum.html#ReduceSumOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceSum.ReduceSumOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ReduceSum.ReduceSumOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSum.html#ReduceSumOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceSum.ReduceSumOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ReduceSum.ReduceSumOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSum.html#ReduceSumOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceSum.ReduceSumOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.ReduceSum.reduce_sum_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ReduceSum.</span></code><code class="sig-name descname"><span class="pre">reduce_sum_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSum.html#reduce_sum_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceSum.reduce_sum_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.sum(node_A, axis, keepdims); Sum of array elements over a given axis.
Make a new instance of ReduceSumOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be summed.</p>
</dd>
<dt><strong>axes</strong><span class="classifier">int or list</span></dt><dd><p>The axis/axes needed to be summed.</p>
</dd>
<dt><strong>keepdims: bool or list, optional, default: False</strong></dt><dd><p>Whether to keep the dimension(s).
From NumPy Doc:
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.
If the default value is passed, then keepdims will not be passed through to the sum method of sub-classes of ndarray, however any non-default value will be. If the sub-class’ method does not implement keepdims any exceptions will be raised.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ReduceSumOp.</dt><dd><p>Return the sum of array elements over a given axis.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.ReduceSumAxisZero">
<span id="hetu-gpu-ops-reducesumaxiszero-module"></span><h2>hetu.gpu_ops.ReduceSumAxisZero module<a class="headerlink" href="#module-hetu.gpu_ops.ReduceSumAxisZero" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ReduceSumAxisZero.</span></code><code class="sig-name descname"><span class="pre">ReduceSumAxisZeroOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSumAxisZero.html#ReduceSumAxisZeroOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.compute" title="hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.gradient" title="hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.infer_shape" title="hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>summation reduction axis = 0 e.g.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSumAxisZero.html#ReduceSumAxisZeroOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSumAxisZero.html#ReduceSumAxisZeroOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSumAxisZero.html#ReduceSumAxisZeroOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceSumAxisZero.ReduceSumAxisZeroOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>summation reduction axis = 0
e.g. (3,4,5)-&gt;(4,5)
for vector, simpler to do (3,)-&gt;(1,)</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.ReduceSumAxisZero.reducesumaxiszero_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ReduceSumAxisZero.</span></code><code class="sig-name descname"><span class="pre">reducesumaxiszero_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSumAxisZero.html#reducesumaxiszero_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ReduceSumAxisZero.reducesumaxiszero_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.sum(node_A, axis=0); Sum of array elements over axis 0.
Make a new instance of ReduceSumAxisZeroOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be summed.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ReduceSumAxisZeroOp.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Relu">
<span id="hetu-gpu-ops-relu-module"></span><h2>hetu.gpu_ops.Relu module<a class="headerlink" href="#module-hetu.gpu_ops.Relu" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Relu.ReluGradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Relu.</span></code><code class="sig-name descname"><span class="pre">ReluGradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#ReluGradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Relu.ReluGradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Relu.ReluGradientOp.compute" title="hetu.gpu_ops.Relu.ReluGradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Relu.ReluGradientOp.gradient" title="hetu.gpu_ops.Relu.ReluGradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Relu.ReluGradientOp.infer_shape" title="hetu.gpu_ops.Relu.ReluGradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Relu.ReluGradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#ReluGradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Relu.ReluGradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Relu.ReluGradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#ReluGradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Relu.ReluGradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Relu.ReluGradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#ReluGradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Relu.ReluGradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.Relu.ReluOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Relu.</span></code><code class="sig-name descname"><span class="pre">ReluOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#ReluOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Relu.ReluOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Relu.ReluOp.compute" title="hetu.gpu_ops.Relu.ReluOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Relu.ReluOp.gradient" title="hetu.gpu_ops.Relu.ReluOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Relu.ReluOp.infer_shape" title="hetu.gpu_ops.Relu.ReluOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Relu.ReluOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#ReluOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Relu.ReluOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Relu.ReluOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#ReluOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Relu.ReluOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Relu.ReluOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#ReluOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Relu.ReluOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Relu.relu_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Relu.</span></code><code class="sig-name descname"><span class="pre">relu_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#relu_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Relu.relu_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the gradient of the ReLU function.  
Make a new instance of ReluGradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Relu input.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Previous gradient node.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ReluGradientOp.</dt><dd><p>Return the gradients of the ReLU function.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Relu.relu_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Relu.</span></code><code class="sig-name descname"><span class="pre">relu_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#relu_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Relu.relu_op" title="Permalink to this definition">¶</a></dt>
<dd><p>ReLU(Rectified Linear Unit) operation.
Make a new instance of ReluOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ReluOp.</dt><dd><p>Return the relu of the input node.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Reshape">
<span id="hetu-gpu-ops-reshape-module"></span><h2>hetu.gpu_ops.Reshape module<a class="headerlink" href="#module-hetu.gpu_ops.Reshape" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Reshape.Array_ReshapeOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Reshape.</span></code><code class="sig-name descname"><span class="pre">Array_ReshapeOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#Array_ReshapeOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.Array_ReshapeOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Reshape.Array_ReshapeOp.compute" title="hetu.gpu_ops.Reshape.Array_ReshapeOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Reshape.Array_ReshapeOp.gradient" title="hetu.gpu_ops.Reshape.Array_ReshapeOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Reshape.Array_ReshapeOp.infer_shape" title="hetu.gpu_ops.Reshape.Array_ReshapeOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Reshape.Array_ReshapeOp.backward_hook">
<code class="sig-name descname"><span class="pre">backward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#Array_ReshapeOp.backward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.Array_ReshapeOp.backward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Reshape.Array_ReshapeOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#Array_ReshapeOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.Array_ReshapeOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Reshape.Array_ReshapeOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#Array_ReshapeOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.Array_ReshapeOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Reshape.Array_ReshapeOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#Array_ReshapeOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.Array_ReshapeOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.Reshape.Array_Reshape_GradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Reshape.</span></code><code class="sig-name descname"><span class="pre">Array_Reshape_GradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#Array_Reshape_GradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.Array_Reshape_GradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.compute" title="hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.gradient" title="hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.infer_shape" title="hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.backward_hook">
<code class="sig-name descname"><span class="pre">backward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#Array_Reshape_GradientOp.backward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.backward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#Array_Reshape_GradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#Array_Reshape_GradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#Array_Reshape_GradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.Array_Reshape_GradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Reshape.array_reshape_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Reshape.</span></code><code class="sig-name descname"><span class="pre">array_reshape_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#array_reshape_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.array_reshape_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Gradient of reshape operation.
Make a new instance of Array_Reshape_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input node of reshape operation.</p>
</dd>
<dt><strong>node_out: Node</strong></dt><dd><p>Previous gradient node.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Array_Reshape_GradientOp.</dt><dd><p>Return the gradient of reshape operation.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Reshape.array_reshape_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Reshape.</span></code><code class="sig-name descname"><span class="pre">array_reshape_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#array_reshape_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Reshape.array_reshape_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshapes an input array node without copy.
Make a new instance of Array_ReshapeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>output_shape: tuple(int)</strong></dt><dd><p>Expected shape of the output array.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Array_ReshapeOp.</dt><dd><p>Return the reshaped array node.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Sigmoid">
<span id="hetu-gpu-ops-sigmoid-module"></span><h2>hetu.gpu_ops.Sigmoid module<a class="headerlink" href="#module-hetu.gpu_ops.Sigmoid" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Sigmoid.SigmoidOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Sigmoid.</span></code><code class="sig-name descname"><span class="pre">SigmoidOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sigmoid.html#SigmoidOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sigmoid.SigmoidOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Sigmoid.SigmoidOp.compute" title="hetu.gpu_ops.Sigmoid.SigmoidOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Sigmoid.SigmoidOp.gradient" title="hetu.gpu_ops.Sigmoid.SigmoidOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Sigmoid.SigmoidOp.infer_shape" title="hetu.gpu_ops.Sigmoid.SigmoidOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Sigmoid.SigmoidOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sigmoid.html#SigmoidOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sigmoid.SigmoidOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Sigmoid.SigmoidOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sigmoid.html#SigmoidOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sigmoid.SigmoidOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Sigmoid.SigmoidOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sigmoid.html#SigmoidOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sigmoid.SigmoidOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Sigmoid.sigmoid_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Sigmoid.</span></code><code class="sig-name descname"><span class="pre">sigmoid_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sigmoid.html#sigmoid_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sigmoid.sigmoid_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sigmoid of a matrix elementwisely.
Make a new instance of SigmoidOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SigmoidOp.</dt><dd><p>Return the sigmoid of a matrix elementwisely.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Slice">
<span id="hetu-gpu-ops-slice-module"></span><h2>hetu.gpu_ops.Slice module<a class="headerlink" href="#module-hetu.gpu_ops.Slice" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Slice.SliceGradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Slice.</span></code><code class="sig-name descname"><span class="pre">SliceGradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin_pos</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#SliceGradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Slice.SliceGradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Slice.SliceGradientOp.compute" title="hetu.gpu_ops.Slice.SliceGradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Slice.SliceGradientOp.gradient" title="hetu.gpu_ops.Slice.SliceGradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Slice.SliceGradientOp.infer_shape" title="hetu.gpu_ops.Slice.SliceGradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Slice.SliceGradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#SliceGradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Slice.SliceGradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Slice.SliceGradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#SliceGradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Slice.SliceGradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Slice.SliceGradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#SliceGradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Slice.SliceGradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.Slice.SliceOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Slice.</span></code><code class="sig-name descname"><span class="pre">SliceOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin_pos</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#SliceOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Slice.SliceOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Slice.SliceOp.compute" title="hetu.gpu_ops.Slice.SliceOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Slice.SliceOp.gradient" title="hetu.gpu_ops.Slice.SliceOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Slice.SliceOp.infer_shape" title="hetu.gpu_ops.Slice.SliceOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Slice.SliceOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#SliceOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Slice.SliceOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Slice.SliceOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#SliceOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Slice.SliceOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Slice.SliceOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#SliceOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Slice.SliceOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Slice.slice_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Slice.</span></code><code class="sig-name descname"><span class="pre">slice_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#slice_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Slice.slice_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents the gradient of tf.slice.
Make a new instance of SliceGradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be sliced.</p>
</dd>
<dt><strong>begin: tuple</strong></dt><dd><p>The beginning position of slice operation.</p>
</dd>
<dt><strong>size: tuple</strong></dt><dd><p>The shape(size) of output tensor.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SliceGradientOp.</dt><dd><p>Return the gradient of slice operation.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Slice.slice_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Slice.</span></code><code class="sig-name descname"><span class="pre">slice_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#slice_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Slice.slice_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents tf.slice(node, begin, size); extracts a slice of size ‘size’ from node starting at location specified by begin.
Make a new instance of SliceOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be sliced.</p>
</dd>
<dt><strong>begin: tuple</strong></dt><dd><p>The beginning position of slice operation.</p>
</dd>
<dt><strong>size: tuple</strong></dt><dd><p>The shape(size) of output tensor.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SliceOp.</dt><dd><p>Return a slice of size ‘size’ from node starting at location specified by begin.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Softmax">
<span id="hetu-gpu-ops-softmax-module"></span><h2>hetu.gpu_ops.Softmax module<a class="headerlink" href="#module-hetu.gpu_ops.Softmax" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Softmax.SoftmaxGradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Softmax.</span></code><code class="sig-name descname"><span class="pre">SoftmaxGradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#SoftmaxGradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.SoftmaxGradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Softmax.SoftmaxGradientOp.compute" title="hetu.gpu_ops.Softmax.SoftmaxGradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Softmax.SoftmaxGradientOp.gradient" title="hetu.gpu_ops.Softmax.SoftmaxGradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Softmax.SoftmaxGradientOp.infer_shape" title="hetu.gpu_ops.Softmax.SoftmaxGradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Softmax.SoftmaxGradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#SoftmaxGradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.SoftmaxGradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Softmax.SoftmaxGradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#SoftmaxGradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.SoftmaxGradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Softmax.SoftmaxGradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#SoftmaxGradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.SoftmaxGradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.Softmax.SoftmaxOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Softmax.</span></code><code class="sig-name descname"><span class="pre">SoftmaxOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#SoftmaxOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.SoftmaxOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Softmax.SoftmaxOp.compute" title="hetu.gpu_ops.Softmax.SoftmaxOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Softmax.SoftmaxOp.gradient" title="hetu.gpu_ops.Softmax.SoftmaxOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Softmax.SoftmaxOp.infer_shape" title="hetu.gpu_ops.Softmax.SoftmaxOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Softmax.SoftmaxOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#SoftmaxOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.SoftmaxOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Softmax.SoftmaxOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#SoftmaxOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.SoftmaxOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Softmax.SoftmaxOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#SoftmaxOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.SoftmaxOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Softmax.softmax_func">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Softmax.</span></code><code class="sig-name descname"><span class="pre">softmax_func</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#softmax_func"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.softmax_func" title="Permalink to this definition">¶</a></dt>
<dd><p>Numerically stable softmax.</p>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Softmax.softmax_gradient_func">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Softmax.</span></code><code class="sig-name descname"><span class="pre">softmax_gradient_func</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dy</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#softmax_gradient_func"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.softmax_gradient_func" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Softmax.softmax_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Softmax.</span></code><code class="sig-name descname"><span class="pre">softmax_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#softmax_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.softmax_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>This function computes softmax gradient.
Make a new instance of SoftmaxGradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_y</strong><span class="classifier">Node</span></dt><dd><p>Output variable of forward softmax.</p>
</dd>
<dt><strong>grad</strong><span class="classifier">Node</span></dt><dd><p>Gradient variable, dy.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SoftmaxGradientOp.</dt><dd><p>Return the gradient of softmax.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Softmax.softmax_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Softmax.</span></code><code class="sig-name descname"><span class="pre">softmax_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#softmax_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Softmax.softmax_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the softmax of node along an axis.
Make a new instance of SoftmaxOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SoftmaxOp.</dt><dd><p>Return the softmax of the input node.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.SoftmaxCrossEntropy">
<span id="hetu-gpu-ops-softmaxcrossentropy-module"></span><h2>hetu.gpu_ops.SoftmaxCrossEntropy module<a class="headerlink" href="#module-hetu.gpu_ops.SoftmaxCrossEntropy" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.SoftmaxCrossEntropy.</span></code><code class="sig-name descname"><span class="pre">SoftmaxCrossEntropyGradientOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cudnn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/SoftmaxCrossEntropy.html#SoftmaxCrossEntropyGradientOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.compute" title="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.gradient" title="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.infer_shape" title="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/SoftmaxCrossEntropy.html#SoftmaxCrossEntropyGradientOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/SoftmaxCrossEntropy.html#SoftmaxCrossEntropyGradientOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/SoftmaxCrossEntropy.html#SoftmaxCrossEntropyGradientOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyGradientOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.SoftmaxCrossEntropy.</span></code><code class="sig-name descname"><span class="pre">SoftmaxCrossEntropyOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cudnn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/SoftmaxCrossEntropy.html#SoftmaxCrossEntropyOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.compute" title="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.gradient" title="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.infer_shape" title="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/SoftmaxCrossEntropy.html#SoftmaxCrossEntropyOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/SoftmaxCrossEntropy.html#SoftmaxCrossEntropyOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/SoftmaxCrossEntropy.html#SoftmaxCrossEntropyOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.SoftmaxCrossEntropy.SoftmaxCrossEntropyOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.SoftmaxCrossEntropy.softmaxcrossentropy_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.SoftmaxCrossEntropy.</span></code><code class="sig-name descname"><span class="pre">softmaxcrossentropy_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cudnn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/SoftmaxCrossEntropy.html#softmaxcrossentropy_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.SoftmaxCrossEntropy.softmaxcrossentropy_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the gradient of cross entropy loss for pre-softmax activations.
Make a new instance of SoftmaxCrossEntropyGradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Predicted probability.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Labels.</p>
</dd>
<dt><strong>node_C</strong><span class="classifier">Node</span></dt><dd><p>Previous gradient node.</p>
</dd>
<dt><strong>use_cudnn</strong><span class="classifier">bool, optional, default: True</span></dt><dd><p>Whether to use cudnn or not.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SoftmaxCrossEntropyGradientOp.</dt><dd><p>Return the gradient of cross entropy loss for pre-softmax activations.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.SoftmaxCrossEntropy.softmaxcrossentropy_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.SoftmaxCrossEntropy.</span></code><code class="sig-name descname"><span class="pre">softmaxcrossentropy_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cudnn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/SoftmaxCrossEntropy.html#softmaxcrossentropy_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.SoftmaxCrossEntropy.softmaxcrossentropy_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes cross entropy loss for pre-softmax activations.
Make a new instance of SoftmaxCrossEntropyOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Predicted probability.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Labels.</p>
</dd>
<dt><strong>use_cudnn</strong><span class="classifier">bool, optional, default: True</span></dt><dd><p>Whether to use cudnn or not.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SoftmaxCrossEntropyOp.</dt><dd><p>Return the cross entropy loss for pre-softmax activations.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Sqrt">
<span id="hetu-gpu-ops-sqrt-module"></span><h2>hetu.gpu_ops.Sqrt module<a class="headerlink" href="#module-hetu.gpu_ops.Sqrt" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Sqrt.ReciprocalSqrtOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Sqrt.</span></code><code class="sig-name descname"><span class="pre">ReciprocalSqrtOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#ReciprocalSqrtOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sqrt.ReciprocalSqrtOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.compute" title="hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.gradient" title="hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.infer_shape" title="hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#ReciprocalSqrtOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#ReciprocalSqrtOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#ReciprocalSqrtOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sqrt.ReciprocalSqrtOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.Sqrt.SqrtOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Sqrt.</span></code><code class="sig-name descname"><span class="pre">SqrtOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#SqrtOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sqrt.SqrtOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Sqrt.SqrtOp.compute" title="hetu.gpu_ops.Sqrt.SqrtOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Sqrt.SqrtOp.gradient" title="hetu.gpu_ops.Sqrt.SqrtOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Sqrt.SqrtOp.infer_shape" title="hetu.gpu_ops.Sqrt.SqrtOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Sqrt.SqrtOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#SqrtOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sqrt.SqrtOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Sqrt.SqrtOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#SqrtOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sqrt.SqrtOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Sqrt.SqrtOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#SqrtOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sqrt.SqrtOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Sqrt.rsqrt_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Sqrt.</span></code><code class="sig-name descname"><span class="pre">rsqrt_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#rsqrt_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sqrt.rsqrt_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the reciprocal of square root of a matrix elementwisely.
Make a new instance of ReciprocalSqrtOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd><p>Return the reciprocal of square root of a matrix node elementwisely.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Sqrt.sqrt_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Sqrt.</span></code><code class="sig-name descname"><span class="pre">sqrt_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#sqrt_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Sqrt.sqrt_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate square root of a matrix elementwisely.
Make a new instance of SqrtOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SqrtOp.</dt><dd><p>Return the square root of a matrix node elementwisely.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Tanh">
<span id="hetu-gpu-ops-tanh-module"></span><h2>hetu.gpu_ops.Tanh module<a class="headerlink" href="#module-hetu.gpu_ops.Tanh" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Tanh.TanhOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Tanh.</span></code><code class="sig-name descname"><span class="pre">TanhOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Tanh.html#TanhOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Tanh.TanhOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Tanh.TanhOp.compute" title="hetu.gpu_ops.Tanh.TanhOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Tanh.TanhOp.gradient" title="hetu.gpu_ops.Tanh.TanhOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Tanh.TanhOp.infer_shape" title="hetu.gpu_ops.Tanh.TanhOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Tanh.TanhOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Tanh.html#TanhOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Tanh.TanhOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Tanh.TanhOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Tanh.html#TanhOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Tanh.TanhOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Tanh.TanhOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Tanh.html#TanhOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Tanh.TanhOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Tanh.tanh_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Tanh.</span></code><code class="sig-name descname"><span class="pre">tanh_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Tanh.html#tanh_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Tanh.tanh_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate tanh of a matrix elementwisely.
Make a new instance of TransposeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by TanhOp.</dt><dd><p>Return the tanh of a matrix node elementwisely.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Transpose">
<span id="hetu-gpu-ops-transpose-module"></span><h2>hetu.gpu_ops.Transpose module<a class="headerlink" href="#module-hetu.gpu_ops.Transpose" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Transpose.TransposeOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Transpose.</span></code><code class="sig-name descname"><span class="pre">TransposeOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Transpose.html#TransposeOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Transpose.TransposeOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Transpose.TransposeOp.compute" title="hetu.gpu_ops.Transpose.TransposeOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Transpose.TransposeOp.gradient" title="hetu.gpu_ops.Transpose.TransposeOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Transpose.TransposeOp.infer_shape" title="hetu.gpu_ops.Transpose.TransposeOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Transpose.TransposeOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Transpose.html#TransposeOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Transpose.TransposeOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Transpose.TransposeOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Transpose.html#TransposeOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Transpose.TransposeOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Transpose.TransposeOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Transpose.html#TransposeOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Transpose.TransposeOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Transpose.transpose_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Transpose.</span></code><code class="sig-name descname"><span class="pre">transpose_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Transpose.html#transpose_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Transpose.transpose_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.transpose; reverse of permute the axes of an array. 
Make a new instance of TransposeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Node to be transposed or permuted.</p>
</dd>
<dt><strong>perm</strong><span class="classifier">tuple or list of ints, optional, default: None</span></dt><dd><p>A permutation of [0,1,..,N-1] where N is the number of axes of node_A.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd><p>Return node_A transposed or with its axes permuted.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Variable">
<span id="hetu-gpu-ops-variable-module"></span><h2>hetu.gpu_ops.Variable module<a class="headerlink" href="#module-hetu.gpu_ops.Variable" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Variable.PlaceholderOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Variable.</span></code><code class="sig-name descname"><span class="pre">PlaceholderOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">name</span></em>, <em class="sig-param"><span class="pre">value=None</span></em>, <em class="sig-param"><span class="pre">initializer=None</span></em>, <em class="sig-param"><span class="pre">trainable=True</span></em>, <em class="sig-param"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></em>, <em class="sig-param"><span class="pre">ctx=None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Variable.html#PlaceholderOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Variable.PlaceholderOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Variable.PlaceholderOp.compute" title="hetu.gpu_ops.Variable.PlaceholderOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Variable.PlaceholderOp.gradient" title="hetu.gpu_ops.Variable.PlaceholderOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Variable.PlaceholderOp.infer_shape" title="hetu.gpu_ops.Variable.PlaceholderOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Variable.PlaceholderOp.backward_hook">
<code class="sig-name descname"><span class="pre">backward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Variable.html#PlaceholderOp.backward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Variable.PlaceholderOp.backward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Variable.PlaceholderOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Variable.html#PlaceholderOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Variable.PlaceholderOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Variable.PlaceholderOp.forward_hook">
<code class="sig-name descname"><span class="pre">forward_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Variable.html#PlaceholderOp.forward_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Variable.PlaceholderOp.forward_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Variable.PlaceholderOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Variable.html#PlaceholderOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Variable.PlaceholderOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Variable.PlaceholderOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Variable.html#PlaceholderOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Variable.PlaceholderOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Variable.Variable">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Variable.</span></code><code class="sig-name descname"><span class="pre">Variable</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'x'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Variable.html#Variable"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Variable.Variable" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>User defined variables in an expression.</dt><dd><p>e.g. x = Variable(name = “x”)</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>name</strong><span class="classifier">str</span></dt><dd><p>Name of the variable.</p>
</dd>
<dt><strong>value</strong><span class="classifier">ndarray.array, optional, default: None</span></dt><dd><p>Specified value of the variable.</p>
</dd>
<dt><strong>initializer</strong><span class="classifier">initializer func, optional, default: None</span></dt><dd><p>The initializer of the variable.</p>
</dd>
<dt><strong>trainable</strong><span class="classifier">bool, optional, default: True</span></dt><dd><p>Whether the variable is trainable.</p>
</dd>
<dt><strong>dtype</strong><span class="classifier">data-type, optional, default: np.float32</span></dt><dd><p>Data type of the variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A Variable, a new Node instance created by PlaceholderOp.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Variable.placeholder_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Variable.</span></code><code class="sig-name descname"><span class="pre">placeholder_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">name</span></em>, <em class="sig-param"><span class="pre">value=None</span></em>, <em class="sig-param"><span class="pre">initializer=None</span></em>, <em class="sig-param"><span class="pre">trainable=True</span></em>, <em class="sig-param"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></em>, <em class="sig-param"><span class="pre">ctx=None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Variable.html#placeholder_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Variable.placeholder_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Node of variable placeholder.
Make a new instance of Node PlaceholderOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>name</strong><span class="classifier">str</span></dt><dd><p>Name of the placeholder.</p>
</dd>
<dt><strong>value</strong><span class="classifier">ndarray.array, optional, default: None</span></dt><dd><p>Specified value of the placeholder.</p>
</dd>
<dt><strong>initializer</strong><span class="classifier">initializer func, optional, default: None</span></dt><dd><p>The initializer of the placeholder.</p>
</dd>
<dt><strong>trainable</strong><span class="classifier">bool, optional, default: True</span></dt><dd><p>Whether the placeholder is trainable.</p>
</dd>
<dt><strong>dtype</strong><span class="classifier">data-type, optional, default: np.float32</span></dt><dd><p>Data type of the placeholder.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by PlaceholderOp.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.Where">
<span id="hetu-gpu-ops-where-module"></span><h2>hetu.gpu_ops.Where module<a class="headerlink" href="#module-hetu.gpu_ops.Where" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Where.WhereOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Where.</span></code><code class="sig-name descname"><span class="pre">WhereOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cond</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Where.html#WhereOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Where.WhereOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Where.WhereOp.compute" title="hetu.gpu_ops.Where.WhereOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Where.WhereOp.gradient" title="hetu.gpu_ops.Where.WhereOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Where.WhereOp.infer_shape" title="hetu.gpu_ops.Where.WhereOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>Given shapes of input nodes, compute shape of output node.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Where.WhereOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Where.html#WhereOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Where.WhereOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Where.WhereOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Where.html#WhereOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Where.WhereOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Where.WhereOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Where.html#WhereOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Where.WhereOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of input nodes, compute shape of output node.
Implementation note:
It’s simpler to treat shape of constants as (1,), so that constants can
be stored as a numpy array too and you would need fewer special case
handling.
Parameters
———-
node: node whose shape is being inferred.
input_vals: shapes of input nodes.
Returns
——-
A tuple representing the shape of output node.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Where.where_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.Where.</span></code><code class="sig-name descname"><span class="pre">where_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cond</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Where.html#where_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Where.where_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.where; Return elements chosen from node_A or node_B depending on cond.
Make a new instance of Node WhereOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>cond</strong><span class="classifier">Node</span></dt><dd><p>Node of a condition array; when True, yield node_A, otherwise yield node_B.</p>
</dd>
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Output if cond.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Output if not cond.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by WhereOp.</dt><dd><p>Return an array node with elements from node_A where cond is True, and elements from node_B elsewhere.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.ZerosLike">
<span id="hetu-gpu-ops-zeroslike-module"></span><h2>hetu.gpu_ops.ZerosLike module<a class="headerlink" href="#module-hetu.gpu_ops.ZerosLike" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.ZerosLike.ZerosLikeOp">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ZerosLike.</span></code><code class="sig-name descname"><span class="pre">ZerosLikeOp</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ZerosLike.html#ZerosLikeOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ZerosLike.ZerosLikeOp" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#hetu.gpu_ops.Node.Op" title="hetu.gpu_ops.Node.Op"><code class="xref py py-class docutils literal notranslate"><span class="pre">hetu.gpu_ops.Node.Op</span></code></a></p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.ZerosLike.ZerosLikeOp.compute" title="hetu.gpu_ops.ZerosLike.ZerosLikeOp.compute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute</span></code></a>(input_vals, output_val[, stream_handle])</p></td>
<td><p>Given values of input nodes, compute the output value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.ZerosLike.ZerosLikeOp.gradient" title="hetu.gpu_ops.ZerosLike.ZerosLikeOp.gradient"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient</span></code></a>(output_grad)</p></td>
<td><p>Given output gradient, compute partial gradient to each input node.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.ZerosLike.ZerosLikeOp.infer_shape" title="hetu.gpu_ops.ZerosLike.ZerosLikeOp.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(input_shapes)</p></td>
<td><p>If input_shape is a vector, simpler to return (1,)</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 66%" />
<col style="width: 34%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>add_transfer_op</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>backward_hook</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>forward_hook</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.ZerosLike.ZerosLikeOp.compute">
<code class="sig-name descname"><span class="pre">compute</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_vals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_handle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ZerosLike.html#ZerosLikeOp.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ZerosLike.ZerosLikeOp.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Given values of input nodes, compute the output value.
Parameters
———-
node: node that performs the compute.
input_vals: values of input nodes.
output_val: output value of the node, modified in-place.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ZerosLike.ZerosLikeOp.gradient">
<code class="sig-name descname"><span class="pre">gradient</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_grad</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ZerosLike.html#ZerosLikeOp.gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ZerosLike.ZerosLikeOp.gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Given output gradient, compute partial gradient to each input node.
Parameters
———-
node: node that performs the gradient.
output_grad: output gradient summed from children nodes’ contributions
Returns
——-
A list of gradient contributions to each input node respectively.</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.ZerosLike.ZerosLikeOp.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ZerosLike.html#ZerosLikeOp.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ZerosLike.ZerosLikeOp.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>If input_shape is a vector, simpler to return (1,)</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.ZerosLike.zeroslike_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.ZerosLike.</span></code><code class="sig-name descname"><span class="pre">zeroslike_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ZerosLike.html#zeroslike_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.ZerosLike.zeroslike_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.zeros(node_A.shape); Return a new array of given shape and type, filled with zeros.
Make a new instance of Node ZerosLikeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to pad with 0.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ZerosLikeOp.</dt><dd><p>Return array node of zeros with the given shape, dtype, and order.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops.executor">
<span id="hetu-gpu-ops-executor-module"></span><h2>hetu.gpu_ops.executor module<a class="headerlink" href="#module-hetu.gpu_ops.executor" title="Permalink to this headline">¶</a></h2>
<p>library to take autodiff and execute a computation graph</p>
<dl class="py class">
<dt id="hetu.gpu_ops.executor.Executor">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">Executor</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eval_node_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.Executor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Executor computes values for given set of nodes in computation graph.</p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.executor.Executor.infer_shape" title="hetu.gpu_ops.executor.Executor.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(feed_shapes)</p></td>
<td><p>Given shapes of feed_dict nodes, infer shape for all nodes in graph.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.executor.Executor.memory_plan" title="hetu.gpu_ops.executor.Executor.memory_plan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">memory_plan</span></code></a>()</p></td>
<td><p>Allocates ndarray.NDArray for every node except feed_dict nodes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.executor.Executor.run" title="hetu.gpu_ops.executor.Executor.run"><code class="xref py py-obj docutils literal notranslate"><span class="pre">run</span></code></a>([feed_dict, convert_to_numpy_ret_vals])</p></td>
<td><p><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p></p></dd>
</dl>
</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>load</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recordLoads</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>save</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.executor.Executor.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feed_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.Executor.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of feed_dict nodes, infer shape for all nodes in graph.</p>
<p>Implementation note:
Iteratively calls node.infer_shape to infer shapes.
Node shapes stored in self.node_to_shape_map.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feed_shapes: node-&gt;shapes mapping for feed_dict nodes.</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.executor.Executor.load">
<code class="sig-name descname"><span class="pre">load</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.Executor.load" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.executor.Executor.memory_plan">
<code class="sig-name descname"><span class="pre">memory_plan</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.memory_plan"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.Executor.memory_plan" title="Permalink to this definition">¶</a></dt>
<dd><p>Allocates ndarray.NDArray for every node except feed_dict nodes.
Parameters
———-</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.executor.Executor.recordLoads">
<code class="sig-name descname"><span class="pre">recordLoads</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.recordLoads"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.Executor.recordLoads" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.executor.Executor.run">
<code class="sig-name descname"><span class="pre">run</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feed_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_numpy_ret_vals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.Executor.run" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feed_dict: a dictionary of node-&gt;np.ndarray supplied by user.</strong></dt><dd></dd>
<dt><strong>convert_to_numpy_ret_vals: whether to convert ret vals to np.array</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A list of values for nodes in eval_node_list. NDArray or np.ndarray.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.executor.Executor.save">
<code class="sig-name descname"><span class="pre">save</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.Executor.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="hetu.gpu_ops.executor.HetuConfig">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">HetuConfig</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eval_node_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">cpu(0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comm_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stream_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'AllStreams'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx_infer_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'use_default'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sparse_pull</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cstable_policy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inference</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bsp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefetch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_lazy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_bound</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#HetuConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>bsp</strong></dt><dd></dd>
<dt><strong>cache_bound</strong></dt><dd></dd>
<dt><strong>comm_mode</strong></dt><dd></dd>
<dt><strong>comp_stream</strong></dt><dd></dd>
<dt><strong>context</strong></dt><dd></dd>
<dt><strong>cstable_policy</strong></dt><dd></dd>
<dt><strong>ctx_infer_mode</strong></dt><dd></dd>
<dt><strong>d2h_ops</strong></dt><dd></dd>
<dt><strong>d2h_stream</strong></dt><dd></dd>
<dt><strong>dataloader_name</strong></dt><dd></dd>
<dt><strong>dataloader_ops</strong></dt><dd></dd>
<dt><strong>enable_lazy</strong></dt><dd></dd>
<dt><strong>eval_node_list</strong></dt><dd></dd>
<dt><strong>h2d_ops</strong></dt><dd></dd>
<dt><strong>h2d_stream</strong></dt><dd></dd>
<dt><strong>inference</strong></dt><dd></dd>
<dt><strong>log_path</strong></dt><dd></dd>
<dt><strong>nccl_comm</strong></dt><dd></dd>
<dt><strong>nccl_stream</strong></dt><dd></dd>
<dt><strong>np_rand</strong></dt><dd></dd>
<dt><strong>prefetch</strong></dt><dd></dd>
<dt><strong>ps_comm</strong></dt><dd></dd>
<dt><strong>ps_map</strong></dt><dd></dd>
<dt><strong>seed</strong></dt><dd></dd>
<dt><strong>stream_mode</strong></dt><dd></dd>
<dt><strong>use_sparse_pull</strong></dt><dd></dd>
<dt><strong>worker_id</strong></dt><dd></dd>
<dt><strong>worker_num</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.bsp">
<code class="sig-name descname"><span class="pre">bsp</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.bsp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.cache_bound">
<code class="sig-name descname"><span class="pre">cache_bound</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.cache_bound" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.comm_mode">
<code class="sig-name descname"><span class="pre">comm_mode</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.comm_mode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.comp_stream">
<code class="sig-name descname"><span class="pre">comp_stream</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.comp_stream" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.context">
<code class="sig-name descname"><span class="pre">context</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.context" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.cstable_policy">
<code class="sig-name descname"><span class="pre">cstable_policy</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.cstable_policy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.ctx_infer_mode">
<code class="sig-name descname"><span class="pre">ctx_infer_mode</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.ctx_infer_mode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.d2h_ops">
<code class="sig-name descname"><span class="pre">d2h_ops</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.d2h_ops" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.d2h_stream">
<code class="sig-name descname"><span class="pre">d2h_stream</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.d2h_stream" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.dataloader_name">
<code class="sig-name descname"><span class="pre">dataloader_name</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.dataloader_name" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.dataloader_ops">
<code class="sig-name descname"><span class="pre">dataloader_ops</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.dataloader_ops" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.enable_lazy">
<code class="sig-name descname"><span class="pre">enable_lazy</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.enable_lazy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.eval_node_list">
<code class="sig-name descname"><span class="pre">eval_node_list</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.eval_node_list" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.h2d_ops">
<code class="sig-name descname"><span class="pre">h2d_ops</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.h2d_ops" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.h2d_stream">
<code class="sig-name descname"><span class="pre">h2d_stream</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.h2d_stream" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.inference">
<code class="sig-name descname"><span class="pre">inference</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.inference" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.log_path">
<code class="sig-name descname"><span class="pre">log_path</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.log_path" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.nccl_comm">
<code class="sig-name descname"><span class="pre">nccl_comm</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.nccl_comm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.nccl_stream">
<code class="sig-name descname"><span class="pre">nccl_stream</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.nccl_stream" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.np_rand">
<code class="sig-name descname"><span class="pre">np_rand</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.np_rand" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.prefetch">
<code class="sig-name descname"><span class="pre">prefetch</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.prefetch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.ps_comm">
<code class="sig-name descname"><span class="pre">ps_comm</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.ps_comm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.ps_map">
<code class="sig-name descname"><span class="pre">ps_map</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.ps_map" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.seed">
<code class="sig-name descname"><span class="pre">seed</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.seed" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.stream_mode">
<code class="sig-name descname"><span class="pre">stream_mode</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.stream_mode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.use_sparse_pull">
<code class="sig-name descname"><span class="pre">use_sparse_pull</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.use_sparse_pull" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.worker_id">
<code class="sig-name descname"><span class="pre">worker_id</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.worker_id" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="hetu.gpu_ops.executor.HetuConfig.worker_num">
<code class="sig-name descname"><span class="pre">worker_num</span></code><a class="headerlink" href="#hetu.gpu_ops.executor.HetuConfig.worker_num" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.broadcast_rule">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">broadcast_rule</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape_a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape_b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#broadcast_rule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.broadcast_rule" title="Permalink to this definition">¶</a></dt>
<dd><p>Return output shape of broadcast shape_a, shape_b.
e.g. broadcast_rule((3,2), (4,3,2))
returns output_shape = (4,3,2)</p>
<p>Check out explanations and more examples at
<a class="reference external" href="https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html">https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html</a>
<a class="reference external" href="http://eli.thegreenplace.net/2015/broadcasting-arrays-in-numpy/">http://eli.thegreenplace.net/2015/broadcasting-arrays-in-numpy/</a></p>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.fetch_dense_parameter_value">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">fetch_dense_parameter_value</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#fetch_dense_parameter_value"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.fetch_dense_parameter_value" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.fetch_sparse_parameter_value">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">fetch_sparse_parameter_value</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#fetch_sparse_parameter_value"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.fetch_sparse_parameter_value" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.find_topo_sort">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">find_topo_sort</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#find_topo_sort"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.find_topo_sort" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a list of nodes, return a topo ordering of nodes ending in them.</p>
<p>A simple algorithm is to do a post-order DFS traversal on the given nodes,
going backwards based on input edges. Since a node is added to the ordering
after all its predecessors are traversed due to post-order DFS, we get a
topological sort.</p>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.find_topo_sort_inference">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">find_topo_sort_inference</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#find_topo_sort_inference"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.find_topo_sort_inference" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.get_nccl_communicate">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">get_nccl_communicate</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#get_nccl_communicate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.get_nccl_communicate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.get_worker_communicate">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">get_worker_communicate</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#get_worker_communicate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.get_worker_communicate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.gradients">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">gradients</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#gradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Take gradient of output node with respect to each node in node_list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>output_node: output node that we are taking derivative of.</strong></dt><dd></dd>
<dt><strong>node_list: list of nodes that we are taking derivative wrt.</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A list of gradient values, one for each node in node_list respectively.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.mpi_nccl_finish">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">mpi_nccl_finish</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">comm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#mpi_nccl_finish"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.mpi_nccl_finish" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.mpi_nccl_init">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">mpi_nccl_init</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#mpi_nccl_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.mpi_nccl_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.new_group_comm">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">new_group_comm</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">group_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#new_group_comm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.new_group_comm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.path_to_lib">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">path_to_lib</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#path_to_lib"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.path_to_lib" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.scheduler_finish">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">scheduler_finish</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#scheduler_finish"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.scheduler_finish" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.scheduler_init">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">scheduler_init</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#scheduler_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.scheduler_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.server_finish">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">server_finish</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#server_finish"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.server_finish" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.server_init">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">server_init</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#server_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.server_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.sum_node_list">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">sum_node_list</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#sum_node_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.sum_node_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Custom sum func to avoid creating redundant nodes in Python sum func.</p>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.topo_sort_dfs">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">topo_sort_dfs</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visited</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topo_order</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#topo_sort_dfs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.topo_sort_dfs" title="Permalink to this definition">¶</a></dt>
<dd><p>Post-order DFS</p>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.topo_sort_dfs_with_hook">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">topo_sort_dfs_with_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visited</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#topo_sort_dfs_with_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.topo_sort_dfs_with_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.topo_sort_with_hook">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">topo_sort_with_hook</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#topo_sort_with_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.topo_sort_with_hook" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.worker_finish">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">worker_finish</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#worker_finish"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.worker_finish" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.executor.worker_init">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.executor.</span></code><code class="sig-name descname"><span class="pre">worker_init</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#worker_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.executor.worker_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-hetu.gpu_ops">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-hetu.gpu_ops" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="hetu.gpu_ops.Executor">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">Executor</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eval_node_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Executor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Executor computes values for given set of nodes in computation graph.</p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Executor.infer_shape" title="hetu.gpu_ops.Executor.infer_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_shape</span></code></a>(feed_shapes)</p></td>
<td><p>Given shapes of feed_dict nodes, infer shape for all nodes in graph.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#hetu.gpu_ops.Executor.memory_plan" title="hetu.gpu_ops.Executor.memory_plan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">memory_plan</span></code></a>()</p></td>
<td><p>Allocates ndarray.NDArray for every node except feed_dict nodes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#hetu.gpu_ops.Executor.run" title="hetu.gpu_ops.Executor.run"><code class="xref py py-obj docutils literal notranslate"><span class="pre">run</span></code></a>([feed_dict, convert_to_numpy_ret_vals])</p></td>
<td><p><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p></p></dd>
</dl>
</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>load</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>recordLoads</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>save</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="hetu.gpu_ops.Executor.infer_shape">
<code class="sig-name descname"><span class="pre">infer_shape</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feed_shapes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.infer_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Executor.infer_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Given shapes of feed_dict nodes, infer shape for all nodes in graph.</p>
<p>Implementation note:
Iteratively calls node.infer_shape to infer shapes.
Node shapes stored in self.node_to_shape_map.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feed_shapes: node-&gt;shapes mapping for feed_dict nodes.</strong></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Executor.load">
<code class="sig-name descname"><span class="pre">load</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Executor.load" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Executor.memory_plan">
<code class="sig-name descname"><span class="pre">memory_plan</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.memory_plan"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Executor.memory_plan" title="Permalink to this definition">¶</a></dt>
<dd><p>Allocates ndarray.NDArray for every node except feed_dict nodes.
Parameters
———-</p>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Executor.recordLoads">
<code class="sig-name descname"><span class="pre">recordLoads</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.recordLoads"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Executor.recordLoads" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Executor.run">
<code class="sig-name descname"><span class="pre">run</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feed_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_numpy_ret_vals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Executor.run" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feed_dict: a dictionary of node-&gt;np.ndarray supplied by user.</strong></dt><dd></dd>
<dt><strong>convert_to_numpy_ret_vals: whether to convert ret vals to np.array</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A list of values for nodes in eval_node_list. NDArray or np.ndarray.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="hetu.gpu_ops.Executor.save">
<code class="sig-name descname"><span class="pre">save</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#Executor.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Executor.save" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.Variable">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">Variable</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'x'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Variable.html#Variable"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.Variable" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>User defined variables in an expression.</dt><dd><p>e.g. x = Variable(name = “x”)</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>name</strong><span class="classifier">str</span></dt><dd><p>Name of the variable.</p>
</dd>
<dt><strong>value</strong><span class="classifier">ndarray.array, optional, default: None</span></dt><dd><p>Specified value of the variable.</p>
</dd>
<dt><strong>initializer</strong><span class="classifier">initializer func, optional, default: None</span></dt><dd><p>The initializer of the variable.</p>
</dd>
<dt><strong>trainable</strong><span class="classifier">bool, optional, default: True</span></dt><dd><p>Whether the variable is trainable.</p>
</dd>
<dt><strong>dtype</strong><span class="classifier">data-type, optional, default: np.float32</span></dt><dd><p>Data type of the variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A Variable, a new Node instance created by PlaceholderOp.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.add_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">add_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddElewise.html#add_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.add_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a node with another.
Make a new instance of Node Addition and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node to be added.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Another Node to be added.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.addbyconst_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">addbyconst_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">const_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AddConst.html#addbyconst_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.addbyconst_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a node with a constant.
Make a new instance of AddByConstOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to be added.</p>
</dd>
<dt><strong>const_val</strong><span class="classifier">scalar value</span></dt><dd><p>The constant value to be added.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.allreduceCommunicate_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">allreduceCommunicate_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#allreduceCommunicate_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.allreduceCommunicate_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce data arrays and leaves identical copies of the result on each processes.
Make a new instance of AllReduceCommunicateOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to do allreduce.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.array_reshape_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">array_reshape_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#array_reshape_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.array_reshape_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Gradient of reshape operation.
Make a new instance of Array_Reshape_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input node of reshape operation.</p>
</dd>
<dt><strong>node_out: Node</strong></dt><dd><p>Previous gradient node.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Array_Reshape_GradientOp.</dt><dd><p>Return the gradient of reshape operation.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.array_reshape_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">array_reshape_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Reshape.html#array_reshape_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.array_reshape_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshapes an input array node without copy.
Make a new instance of Array_ReshapeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>output_shape: tuple(int)</strong></dt><dd><p>Expected shape of the output array.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Array_ReshapeOp.</dt><dd><p>Return the reshaped array node.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.avg_pool2d_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">avg_pool2d_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_out_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#avg_pool2d_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.avg_pool2d_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of average pooling node.
Make a new instance of Avg_Pool2d_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_out</strong><span class="classifier">Node</span></dt><dd><p>Output node of average pooling.</p>
</dd>
<dt><strong>node_out_gradient</strong><span class="classifier">Node</span></dt><dd><p>Previous gradient node.</p>
</dd>
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input node of average pooling.</p>
</dd>
<dt><strong>kernel_H</strong><span class="classifier">Int</span></dt><dd><p>Kernel height.</p>
</dd>
<dt><strong>kernel_W</strong><span class="classifier">Int</span></dt><dd><p>Kernel width.</p>
</dd>
<dt><strong>padding</strong><span class="classifier">Int</span></dt><dd><p>Padding size.</p>
</dd>
<dt><strong>stride</strong><span class="classifier">Int</span></dt><dd><p>Stride size.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.avg_pool2d_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">avg_pool2d_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AvgPool.html#avg_pool2d_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.avg_pool2d_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D average pooling over an input signal.
Make a new instance of Avg_Pool2dOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Input node.</p>
</dd>
<dt><strong>kernel_H</strong><span class="classifier">Int</span></dt><dd><p>Kernel height.</p>
</dd>
<dt><strong>kernel_W</strong><span class="classifier">Int</span></dt><dd><p>Kernel width.</p>
</dd>
<dt><strong>padding</strong><span class="classifier">Int</span></dt><dd><p>Padding size.</p>
</dd>
<dt><strong>stride</strong><span class="classifier">Int</span></dt><dd><p>Stride size.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.batch_matmul_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">batch_matmul_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_A</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_B</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchMatrixMult.html#batch_matmul_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.batch_matmul_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiplies slices of two matrices in batches.
Make a new instance of Batch Matrix Multiplication and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The left operand of the matrix multiplication.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The right operand of the matrix multiplication.</p>
</dd>
<dt><strong>trans_A</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_A to be transposed</p>
</dd>
<dt><strong>trans_B</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_B to be transposed</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.batch_normalization_gradient_of_bias_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">batch_normalization_gradient_of_bias_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bn_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batch_normalization_gradient_of_bias_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.batch_normalization_gradient_of_bias_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the bias parameter’s gradient of batch normalization node.
Make a new instance of Node Batch_Normalization_Gradient_of_ScaleOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>bn_gradient :</strong></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_bias :</strong></dt><dd><p>Bias parameter of bn layer.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.batch_normalization_gradient_of_data_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">batch_normalization_gradient_of_data_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bn_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_arr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batch_normalization_gradient_of_data_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.batch_normalization_gradient_of_data_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the data’s gradient of batch normalization node.
Make a new instance of Node Batch_Normalization_Gradient_of_DataOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>bn_gradient :</strong></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_arr</strong><span class="classifier">Node</span></dt><dd><p>Input array of bn layer.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.batch_normalization_gradient_of_scale_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">batch_normalization_gradient_of_scale_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bn_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batch_normalization_gradient_of_scale_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.batch_normalization_gradient_of_scale_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the scale parameter’s gradient of batch normalization node.
Make a new instance of Node Batch_Normalization_Gradient_of_ScaleOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>bn_gradient :</strong></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_scale :</strong></dt><dd><p>Scaling parameter of bn layer.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.batch_normalization_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">batch_normalization_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batch_normalization_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.batch_normalization_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of batch normalization node.
Make a new instance of Node Batch_Normalization_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>out_gradient</strong><span class="classifier">Node</span></dt><dd><p>The gradient array.</p>
</dd>
<dt><strong>in_node</strong><span class="classifier">Node</span></dt><dd><p>Input node of bn layer.</p>
</dd>
<dt><strong>bn_scale</strong><span class="classifier">Node</span></dt><dd><p>Scaling parameter.</p>
</dd>
<dt><strong>forward_node</strong><span class="classifier">Node</span></dt><dd><p>The forward node.</p>
</dd>
<dt><strong>eps</strong><span class="classifier">float</span></dt><dd><p>Epsilon value for numerical stability.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.batch_normalization_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">batch_normalization_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BatchNorm.html#batch_normalization_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.batch_normalization_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalizes a matrix by mean and variance, and applies a scale to it, as well as a bias.
Make a new instance of Node Batch_NormalizationOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input data.</p>
</dd>
<dt><strong>bn_scale</strong><span class="classifier">Node</span></dt><dd><p>scaling parameter</p>
</dd>
<dt><strong>bn_bias</strong><span class="classifier">Node</span></dt><dd><p>learnable bias parameter</p>
</dd>
<dt><strong>momentum</strong><span class="classifier">float</span></dt><dd><p>Acting on the calculation of mean and variance, the mean and variance values in historical batch are retained.</p>
</dd>
<dt><strong>eps</strong><span class="classifier">float</span></dt><dd><p>Epsilon value for numerical stability.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.binarycrossentropy_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">binarycrossentropy_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BinaryCrossEntropy.html#binarycrossentropy_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.binarycrossentropy_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes cross entropy loss for pre-softmax activations.
Make a new instance of Node BinaryCrossEntropyOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Predicted probability.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Labels.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.broadcast_shape_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">broadcast_shape_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/BroadcastShape.html#broadcast_shape_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.broadcast_shape_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Broadcast an array to the target shape.
Make a new instance of BroadcastShapeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_a</strong><span class="classifier">Node</span></dt><dd><p>The Node to be broadcast.</p>
</dd>
<dt><strong>shape</strong><span class="classifier">tuple</span></dt><dd><p>Target shape.</p>
</dd>
<dt><strong>add_axes</strong><span class="classifier">tuple</span></dt><dd><p>The axes to be added.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.broadcastto_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">broadcastto_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Broadcast.html#broadcastto_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.broadcastto_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Broadcast one node’s shape to another.
Make a new instance of BroadcastToOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_a</strong><span class="classifier">Node</span></dt><dd><p>The Node to be broadcast.</p>
</dd>
<dt><strong>node_b</strong><span class="classifier">Node</span></dt><dd><p>Another Node with the target shape.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.concat_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">concat_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#concat_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.concat_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of concat node.
Make a new instance of Node Concat_gradientOP and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>grad_node</strong><span class="classifier">Node</span></dt><dd><p>Previous gradient node.</p>
</dd>
<dt><strong>input_node</strong><span class="classifier">Node</span></dt><dd><p>The node to be concatenate.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">Int</span></dt><dd><p>Axis along which to be concatenated.</p>
</dd>
<dt><strong>idx</strong><span class="classifier">Int</span></dt><dd><p>The index of concatenation.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.concat_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">concat_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Concat.html#concat_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.concat_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenates given variables along an axis.
Make a new instance of Node ConcatOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The first node to be concatenate.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The second node to be concatenate.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">Int</span></dt><dd><p>The axis along which two nodes are concatenate.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.conv2d_broadcastto_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">conv2d_broadcastto_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dBroadcast.html#conv2d_broadcastto_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.conv2d_broadcastto_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Broadcast one’s shape to another and interchange axes 1 and 3.
Make a new instance of Node Conv2d_BroadcastToOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node to be broadcast.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Another Node with the target shape.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.conv2d_gradient_of_data_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">conv2d_gradient_of_data_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#conv2d_gradient_of_data_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.conv2d_gradient_of_data_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the data’s gradient of conv2d node.
Make a new instance of Node Conv2d_Gradient_of_DataOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Filter node.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Previous gradient node.</p>
</dd>
<dt><strong>padding</strong><span class="classifier">Int</span></dt><dd><p>Padding size.</p>
</dd>
<dt><strong>stride</strong><span class="classifier">Int</span></dt><dd><p>Stride size.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.conv2d_gradient_of_filter_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">conv2d_gradient_of_filter_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#conv2d_gradient_of_filter_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.conv2d_gradient_of_filter_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the filter’s gradient of conv2d node.
Make a new instance of Node Conv2d_Gradient_of_FilterOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>input_X</strong><span class="classifier">Node</span></dt><dd><p>Input data of conv2d.</p>
</dd>
<dt><strong>gradient_Y</strong><span class="classifier">Node</span></dt><dd><p>Gradient array.</p>
</dd>
<dt><strong>padding</strong><span class="classifier">Int</span></dt><dd><p>Padding size.</p>
</dd>
<dt><strong>stride</strong><span class="classifier">Int</span></dt><dd><p>Stride size.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.conv2d_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">conv2d_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2d.html#conv2d_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.conv2d_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a 2-D convolution.
Make a new instance of Node Conv2dOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Input data node.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Input filter node.</p>
</dd>
<dt><strong>padding</strong><span class="classifier">Int</span></dt><dd><p>Padding size.</p>
</dd>
<dt><strong>stride</strong><span class="classifier">Int</span></dt><dd><p>Stride size.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.conv2d_reducesum_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">conv2d_reducesum_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Conv2dReduceSum.html#conv2d_reducesum_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.conv2d_reducesum_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Sum of array elements over axis=(0,2,3).
Make a new instance of Node Conv2d_ReduceSumOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be summed.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.csrmm_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">csrmm_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_A</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_B</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#csrmm_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.csrmm_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiply a sparse matrix with a dense matrix.
Make a new instance of Node CsrmmOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The left operand, a sparse matrix.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The right operand, a dense matrix.</p>
</dd>
<dt><strong>trans_A</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_A to be transposed, default to be False.</p>
</dd>
<dt><strong>trans_B</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_B to be transposed, default to be False.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.csrmv_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">csrmv_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/CuSparse.html#csrmv_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.csrmv_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiply a sparse matrix with a vector.
Make a new instance of Node CsrmvOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The left operand, a sparse matrix.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The right operand, a vector.</p>
</dd>
<dt><strong>trans</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_A to be transposed, default to be False.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.datad2h_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">datad2h_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#datad2h_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.datad2h_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Transfer data from device(GPU) to host(CPU).
Make a new instance of Node DataD2HOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.datah2d_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">datah2d_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DataTransfer.html#datah2d_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.datah2d_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Transfer data from host(CPU) to device(GPU).
Make a new instance of Node DataH2DOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.distgcn_15d_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">distgcn_15d_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_C</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_Count_Self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_Count_All</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replication</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">comm_groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[None,</span> <span class="pre">None]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">need_W</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/DistGCN_15d.html#distgcn_15d_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.distgcn_15d_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Implementation of 1.5 dimension distributed graph neural network training.
Make a new instance of Node DistGCN_15dOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The adjacency matrix.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The feature matrix.</p>
</dd>
<dt><strong>node_C</strong><span class="classifier">Node</span></dt><dd><p>The weight matrix.</p>
</dd>
<dt><strong>node_Count_Self</strong><span class="classifier">Int</span></dt><dd><p>The count of nodes which current process has.</p>
</dd>
<dt><strong>node_Count_All :Int</strong></dt><dd><p>The count of total nodes.</p>
</dd>
<dt><strong>size</strong><span class="classifier">Int</span></dt><dd><p>The number of processes.</p>
</dd>
<dt><strong>replication</strong><span class="classifier">Int</span></dt><dd><p>The number of replication.</p>
</dd>
<dt><strong>device_id</strong><span class="classifier">Int</span></dt><dd><p>The device id.</p>
</dd>
<dt><strong>comm</strong><span class="classifier">MPI_NCCL_Communicator</span></dt><dd><p>The whole communicator.</p>
</dd>
<dt><strong>comm_groups</strong><span class="classifier">List</span></dt><dd><p>The list of group communicators.</p>
</dd>
<dt><strong>need_W</strong><span class="classifier">Boolean</span></dt><dd><p>Whether need weight matrix, default to be True.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.div_const_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">div_const_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">const_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#div_const_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.div_const_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Divide a matrix by a constant.
Make a new instance of Node DivConstOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>const_val: scalar value</strong></dt><dd><p>The constant value to be multiplied.</p>
</dd>
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node where elements are denominators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.div_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">div_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Division.html#div_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.div_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Divide a matrix with another matrix.
Make a new instance of Node DivOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node where elements are numerators.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Another Node where elements are denominators.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.dropout_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">dropout_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_prob</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forward_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#dropout_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.dropout_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of drop out node.
Make a new instance of Node Dropout_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>keep_prob</strong><span class="classifier">float</span></dt><dd><p>Probability of the results to be kept.</p>
</dd>
<dt><strong>forward_node</strong><span class="classifier">Node</span></dt><dd><p>The forward node .</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.dropout_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">dropout_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_prob</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Dropout.html#dropout_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.dropout_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Drop elements of input variable randomly.
Make a new instance of Node DropoutOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>keep_prob</strong><span class="classifier">float</span></dt><dd><p>Probability of the results to be kept.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.embedding_lookup_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">embedding_lookup_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vectors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#embedding_lookup_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.embedding_lookup_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of embedding lookUp node.
Make a new instance of EmbeddingLookUp_Gradient and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>vectors</strong><span class="classifier">Node</span></dt><dd><p>Vectors which looked up from Embedding.</p>
</dd>
<dt><strong>index</strong><span class="classifier">Node</span></dt><dd><p>The index to be looked up.</p>
</dd>
<dt><strong>embed_shape</strong><span class="classifier">tuple</span></dt><dd><p>The shape of embedding.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.embedding_lookup_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">embedding_lookup_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/EmbeddingLookUp.html#embedding_lookup_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.embedding_lookup_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Find a vector in the embedding table according to specified index.
Make a new instance of EmbeddingLookUp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>embedding</strong><span class="classifier">Node</span></dt><dd><p>The Node of Embedding.</p>
</dd>
<dt><strong>index</strong><span class="classifier">Node</span></dt><dd><p>The index to be looked up.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.gradients">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">gradients</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#gradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Take gradient of output node with respect to each node in node_list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>output_node: output node that we are taking derivative of.</strong></dt><dd></dd>
<dt><strong>node_list: list of nodes that we are taking derivative wrt.</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A list of gradient values, one for each node in node_list respectively.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.groupallreduceCommunicate_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">groupallreduceCommunicate_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_comm</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/AllReduceCommunicate.html#groupallreduceCommunicate_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.groupallreduceCommunicate_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Reduce data arrays and leaves identical copies of the result on each processes in group.
Make a new instance of GroupAllReduceCommunicateOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to do groupallreduce.</p>
</dd>
<dt><strong>group_comm</strong><span class="classifier">MPI_NCCL_Communicator</span></dt><dd><p>The group communicators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.layer_normalization_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">layer_normalization_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ln_scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ln_bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/LayerNorm.html#layer_normalization_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.layer_normalization_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Layer normalization.
Make a new instance of Node Layer_NormalizationOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input data.</p>
</dd>
<dt><strong>ln_scale</strong><span class="classifier">float</span></dt><dd><p>scaling parameter</p>
</dd>
<dt><strong>ln_bias</strong><span class="classifier">float</span></dt><dd><p>learnable bias parameter</p>
</dd>
<dt><strong>eps</strong><span class="classifier">float</span></dt><dd><p>Epsilon value for numerical stability.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.matmul_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">matmul_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_A</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trans_B</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixMult.html#matmul_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.matmul_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Multiply a matrix with another.
Make a new instance of Node MatMulOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The left operand of the matrix multiplication.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>The right operand of the matrix multiplication.</p>
</dd>
<dt><strong>trans_A</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_A to be transposed, default to be False.</p>
</dd>
<dt><strong>trans_B</strong><span class="classifier">Boolean</span></dt><dd><p>Whether node_B to be transposed, default to be False.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.matrix_dot_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">matrix_dot_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MatrixDot.html#matrix_dot_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.matrix_dot_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the elementwise multiplication of two matrixs.
Make a new instance of MatrixDotOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_a</strong><span class="classifier">Node</span></dt><dd><p>The Node to be multiplied.</p>
</dd>
<dt><strong>node_b</strong><span class="classifier">Node</span></dt><dd><p>Another Node to be multiplied.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by MatrixDotOp.</dt><dd><p>Return the elementwise multiplication of two matrixs.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.max_pool2d_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">max_pool2d_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_out</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_out_gradient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_in</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#max_pool2d_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.max_pool2d_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the gradient of max pooling node.
Make a new instance of Max_Pool2d_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_out</strong><span class="classifier">Node</span></dt><dd><p>Output Node</p>
</dd>
<dt><strong>node_out_gradient</strong><span class="classifier">Node</span></dt><dd><p>Gradient array</p>
</dd>
<dt><strong>node_in</strong><span class="classifier">Node</span></dt><dd><p>Input Node</p>
</dd>
<dt><strong>kernel_H</strong><span class="classifier">scalar value</span></dt><dd><p>Size of pool(height)</p>
</dd>
<dt><strong>kernel_W</strong><span class="classifier">scalar value</span></dt><dd><p>Size of pool(width)</p>
</dd>
<dt><strong>padding</strong><span class="classifier">scalar value</span></dt><dd><p>Padding edge</p>
</dd>
<dt><strong>stride</strong><span class="classifier">scalar value</span></dt><dd><p>Step Length of the kernel</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.max_pool2d_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">max_pool2d_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_W</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MaxPool.html#max_pool2d_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.max_pool2d_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform the max pooling on the input node.
Make a new instance of Max_Pool2dOp and call the instance.</p>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.mul_byconst_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">mul_byconst_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">const_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyConst.html#mul_byconst_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.mul_byconst_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the multiplication of a matrix and a const value.
Make a new instance of MulByConstOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to be multiplied.</p>
</dd>
<dt><strong>const_val</strong><span class="classifier">scalar value</span></dt><dd><p>The constant value to be mutiplied.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by MulByConstOp.</dt><dd><p>Return the elementwise multiplication of an node and a const value.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.mul_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">mul_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/MultiplyElewise.html#mul_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.mul_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the elementwise multiplication of two arrays.
Make a new instance of MulOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_a</strong><span class="classifier">Node</span></dt><dd><p>The Node to be multiplied.</p>
</dd>
<dt><strong>node_b</strong><span class="classifier">Node</span></dt><dd><p>Another Node to be multiplied.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by MulOp.</dt><dd><p>Return the elementwise multiplication of two arrays.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.one_hot_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">one_hot_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OneHot.html#one_hot_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.one_hot_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents one hot.
Make a new instance of OneHotOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The input Node.</p>
</dd>
<dt><strong>num_classes: int</strong></dt><dd><p>Number of classes.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by OneHotOp.</dt><dd><p>Return the one hot representation of the input node.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.oneslike_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">oneslike_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/OnesLike.html#oneslike_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.oneslike_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.ones(node_A.shape); Return a new array of given shape and type, filled with ones.
Make a new instance of OnesLikeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to pad with 1.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by OnesLikeOp.</dt><dd><p>Return a new array of ones with given shape, dtype, and order.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.opposite_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">opposite_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Opposite.html#opposite_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.opposite_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the opposite of a matrix elementwisely.
Make a new instance of OppositeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by OppositeOp.</dt><dd><p>Return the opposite of a matrix node elementwisely.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.pad_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">pad_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'CONSTANT'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#pad_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.pad_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents the gradients of np.pad.
Make a new instance of Pad_GradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node to be padded.</p>
</dd>
<dt><strong>paddings</strong><span class="classifier">Node</span></dt><dd><p>Number of values padded to the edges of each axis.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">str, optional, default: CONSTANT</span></dt><dd><p>Padding mode: CONSTANT/REFLECT/SYMMETRIC</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Pad_GradientOp.</dt><dd><p>Return the gradient of padding operation.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.pad_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">pad_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'CONSTANT'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constant_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Pad.html#pad_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.pad_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.pad; pad an input variable.
Make a new instance of PadOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>The Node to be padded.</p>
</dd>
<dt><strong>paddings</strong><span class="classifier">Node</span></dt><dd><p>Number of values padded to the edges of each axis.</p>
</dd>
<dt><strong>mode</strong><span class="classifier">str, optional, default: CONSTANT</span></dt><dd><p>Padding mode: CONSTANT/REFLECT/SYMMETRIC</p>
</dd>
<dt><strong>constant_values: scalar value, optional, default: 0</strong></dt><dd><p>Padding values.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by PadOp.</dt><dd><p>Return the padded array node.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.parameterServerCommunicate_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">parameterServerCommunicate_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#parameterServerCommunicate_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.parameterServerCommunicate_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a node for the communication with parameter server.
Make a new instance of ParameterServerCommunicateOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to do allreduce.</p>
</dd>
<dt><strong>parameter: Node</strong></dt><dd><p>The parameter Node that corresponding to the gradient.</p>
</dd>
<dt><strong>optimizer: Optimizer object</strong></dt><dd><p>The optimizer to use.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ParameterServerCommunicateOp.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.parameterServerSparsePull_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">parameterServerSparsePull_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deps_node</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ParameterServerCommunicate.html#parameterServerSparsePull_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.parameterServerSparsePull_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a node for the Sparse Pull communication with parameter server.
Make a new instance of ParameterServerCommunicateOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>parameter: Node</strong></dt><dd><p>The parameter Node that corresponding to the gradient.</p>
</dd>
<dt><strong>deps_node</strong><span class="classifier">Node</span></dt><dd><p>The Node to do Pull data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ParameterServerSparsePullOp.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.placeholder_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">placeholder_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">name</span></em>, <em class="sig-param"><span class="pre">value=None</span></em>, <em class="sig-param"><span class="pre">initializer=None</span></em>, <em class="sig-param"><span class="pre">trainable=True</span></em>, <em class="sig-param"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></em>, <em class="sig-param"><span class="pre">ctx=None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Variable.html#placeholder_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.placeholder_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Node of variable placeholder.
Make a new instance of Node PlaceholderOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>name</strong><span class="classifier">str</span></dt><dd><p>Name of the placeholder.</p>
</dd>
<dt><strong>value</strong><span class="classifier">ndarray.array, optional, default: None</span></dt><dd><p>Specified value of the placeholder.</p>
</dd>
<dt><strong>initializer</strong><span class="classifier">initializer func, optional, default: None</span></dt><dd><p>The initializer of the placeholder.</p>
</dd>
<dt><strong>trainable</strong><span class="classifier">bool, optional, default: True</span></dt><dd><p>Whether the placeholder is trainable.</p>
</dd>
<dt><strong>dtype</strong><span class="classifier">data-type, optional, default: np.float32</span></dt><dd><p>Data type of the placeholder.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by PlaceholderOp.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.reduce_mean_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">reduce_mean_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceMean.html#reduce_mean_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.reduce_mean_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.mean(node_A, axis, keepdims); Average of array elements over a given axis.
Make a new instance of ReduceMeanOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be averaged.</p>
</dd>
<dt><strong>axes</strong><span class="classifier">int or list</span></dt><dd><p>The axis/axes needed to be averaged.</p>
</dd>
<dt><strong>keepdims: bool or list</strong></dt><dd><p>Whether to keep the dimension(s).</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ReduceMeanOp.</dt><dd><p>Return the average of array elements over a given axis.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.reduce_sum_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">reduce_sum_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">axes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSum.html#reduce_sum_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.reduce_sum_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.sum(node_A, axis, keepdims); Sum of array elements over a given axis.
Make a new instance of ReduceSumOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be summed.</p>
</dd>
<dt><strong>axes</strong><span class="classifier">int or list</span></dt><dd><p>The axis/axes needed to be summed.</p>
</dd>
<dt><strong>keepdims: bool or list, optional, default: False</strong></dt><dd><p>Whether to keep the dimension(s).
From NumPy Doc:
If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array.
If the default value is passed, then keepdims will not be passed through to the sum method of sub-classes of ndarray, however any non-default value will be. If the sub-class’ method does not implement keepdims any exceptions will be raised.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ReduceSumOp.</dt><dd><p>Return the sum of array elements over a given axis.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.reducesumaxiszero_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">reducesumaxiszero_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ReduceSumAxisZero.html#reducesumaxiszero_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.reducesumaxiszero_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.sum(node_A, axis=0); Sum of array elements over axis 0.
Make a new instance of ReduceSumAxisZeroOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be summed.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ReduceSumAxisZeroOp.</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.relu_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">relu_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#relu_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.relu_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the gradient of the ReLU function.  
Make a new instance of ReluGradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Relu input.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Previous gradient node.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ReluGradientOp.</dt><dd><p>Return the gradients of the ReLU function.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.relu_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">relu_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Relu.html#relu_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.relu_op" title="Permalink to this definition">¶</a></dt>
<dd><p>ReLU(Rectified Linear Unit) operation.
Make a new instance of ReluOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ReluOp.</dt><dd><p>Return the relu of the input node.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.rsqrt_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">rsqrt_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#rsqrt_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.rsqrt_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the reciprocal of square root of a matrix elementwisely.
Make a new instance of ReciprocalSqrtOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd><p>Return the reciprocal of square root of a matrix node elementwisely.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.scheduler_finish">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">scheduler_finish</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#scheduler_finish"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.scheduler_finish" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.scheduler_init">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">scheduler_init</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#scheduler_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.scheduler_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.server_finish">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">server_finish</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#server_finish"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.server_finish" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.server_init">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">server_init</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#server_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.server_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.sigmoid_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">sigmoid_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sigmoid.html#sigmoid_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.sigmoid_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sigmoid of a matrix elementwisely.
Make a new instance of SigmoidOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SigmoidOp.</dt><dd><p>Return the sigmoid of a matrix elementwisely.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.slice_gradient_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">slice_gradient_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#slice_gradient_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.slice_gradient_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents the gradient of tf.slice.
Make a new instance of SliceGradientOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be sliced.</p>
</dd>
<dt><strong>begin: tuple</strong></dt><dd><p>The beginning position of slice operation.</p>
</dd>
<dt><strong>size: tuple</strong></dt><dd><p>The shape(size) of output tensor.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SliceGradientOp.</dt><dd><p>Return the gradient of slice operation.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.slice_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">slice_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">begin</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Slice.html#slice_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.slice_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents tf.slice(node, begin, size); extracts a slice of size ‘size’ from node starting at location specified by begin.
Make a new instance of SliceOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node needed to be sliced.</p>
</dd>
<dt><strong>begin: tuple</strong></dt><dd><p>The beginning position of slice operation.</p>
</dd>
<dt><strong>size: tuple</strong></dt><dd><p>The shape(size) of output tensor.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SliceOp.</dt><dd><p>Return a slice of size ‘size’ from node starting at location specified by begin.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.softmax_func">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">softmax_func</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#softmax_func"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.softmax_func" title="Permalink to this definition">¶</a></dt>
<dd><p>Numerically stable softmax.</p>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.softmax_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">softmax_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Softmax.html#softmax_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.softmax_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the softmax of node along an axis.
Make a new instance of SoftmaxOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SoftmaxOp.</dt><dd><p>Return the softmax of the input node.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.softmaxcrossentropy_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">softmaxcrossentropy_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cudnn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/SoftmaxCrossEntropy.html#softmaxcrossentropy_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.softmaxcrossentropy_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes cross entropy loss for pre-softmax activations.
Make a new instance of SoftmaxCrossEntropyOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Predicted probability.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Labels.</p>
</dd>
<dt><strong>use_cudnn</strong><span class="classifier">bool, optional, default: True</span></dt><dd><p>Whether to use cudnn or not.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SoftmaxCrossEntropyOp.</dt><dd><p>Return the cross entropy loss for pre-softmax activations.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.sqrt_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">sqrt_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Sqrt.html#sqrt_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.sqrt_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate square root of a matrix elementwisely.
Make a new instance of SqrtOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by SqrtOp.</dt><dd><p>Return the square root of a matrix node elementwisely.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.tanh_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">tanh_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Tanh.html#tanh_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.tanh_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate tanh of a matrix elementwisely.
Make a new instance of TransposeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>Input variable.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by TanhOp.</dt><dd><p>Return the tanh of a matrix node elementwisely.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.transpose_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">transpose_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Transpose.html#transpose_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.transpose_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.transpose; reverse of permute the axes of an array. 
Make a new instance of TransposeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Node to be transposed or permuted.</p>
</dd>
<dt><strong>perm</strong><span class="classifier">tuple or list of ints, optional, default: None</span></dt><dd><p>A permutation of [0,1,..,N-1] where N is the number of axes of node_A.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by Op.</dt><dd><p>Return node_A transposed or with its axes permuted.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.where_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">where_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cond</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">node_B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/Where.html#where_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.where_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.where; Return elements chosen from node_A or node_B depending on cond.
Make a new instance of Node WhereOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>cond</strong><span class="classifier">Node</span></dt><dd><p>Node of a condition array; when True, yield node_A, otherwise yield node_B.</p>
</dd>
<dt><strong>node_A</strong><span class="classifier">Node</span></dt><dd><p>Output if cond.</p>
</dd>
<dt><strong>node_B</strong><span class="classifier">Node</span></dt><dd><p>Output if not cond.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by WhereOp.</dt><dd><p>Return an array node with elements from node_A where cond is True, and elements from node_B elsewhere.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.worker_finish">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">worker_finish</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#worker_finish"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.worker_finish" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.worker_init">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">worker_init</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/executor.html#worker_init"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.worker_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="hetu.gpu_ops.zeroslike_op">
<code class="sig-prename descclassname"><span class="pre">hetu.gpu_ops.</span></code><code class="sig-name descname"><span class="pre">zeroslike_op</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">node</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ctx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/hetu/gpu_ops/ZerosLike.html#zeroslike_op"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#hetu.gpu_ops.zeroslike_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a node that represents np.zeros(node_A.shape); Return a new array of given shape and type, filled with zeros.
Make a new instance of Node ZerosLikeOp and call the instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>node</strong><span class="classifier">Node</span></dt><dd><p>The Node to pad with 0.</p>
</dd>
<dt><strong>ctx</strong><span class="classifier">DLContext, optional, default: None</span></dt><dd><p>The context of op.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>A new Node instance created by ZerosLikeOp.</dt><dd><p>Return array node of zeros with the given shape, dtype, and order.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, AlfredWangyj.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>